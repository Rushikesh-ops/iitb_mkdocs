{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>This document is the user manual for the PARAM Rudra Supercomputing facility at IUAC Delhi. It covers a wide range of topics ranging from a detailed description of the hardware infrastructure to the information required to utilize the supercomputer, such as information about logging on to the supercomputer, submitting jobs, retrieving the results on to the user's Laptop/ Desktop etc. In short, the manual describes all that one needs to know to effectively utilize PARAM Rudra.</p> <p>The supercomputer PARAM Rudra is based on heterogeneous and hybrid configuration of Intel Xeon 2nd Gen Cascade Lake processors, and NVIDIA Ampere A100 GPU cards. The system was designed and implemented by HPC Technologies group, Centre for Development of Advanced Computing (C-DAC).</p> <p>It consists of 10 Login nodes, 2 visualization nodes, 8 Management and 599 (CPU+GPU+HM) compute nodes with total peak computing capacity of (CPU+GPU+HM) 3.1 PFLOPS.</p>"},{"location":"Page2-SAAC/","title":"System Architecture and Configuration","text":""},{"location":"Page2-SAAC/#system-hardware-specifications","title":"System Hardware Specifications","text":"<p>PARAM Rudra system is based on the Intel Xeon Gold 6240R with a total peak performance of 3.1 PFLOPS. The cluster consists of compute nodes connected with the InfiniBand HDR100 Low-Latency, High-Bandwidth InfiniBand interconnect network. The system uses the Lustre parallel file system.</p> <ul> <li> <p>Total number of Nodes: 619 (20 + 599)</p> </li> <li> <p>Login Nodes: 10</p> </li> <li> <p>Management Nodes: 10</p> </li> <li> <p>CPU only Nodes: 473</p> </li> <li> <p>GPU Nodes: 30</p> </li> <li> <p>GPU ready Nodes: 32</p> </li> <li> <p>High Memory CPU only Nodes: 64</p> </li> </ul>"},{"location":"Page2-SAAC/#login-nodes","title":"Login Nodes","text":"<p>Login nodes are typically used for administrative tasks such as editing, writing scripts, transferring files, managing your jobs and the like. You will always get connected to one of the login nodes. From the login nodes you can get connected to a Compute Node and execute an interactive job or submit batch jobs through the batch system (SLURM) to run your jobs on compute nodes. For all users PARAM Rudra Login Nodes are the entry points and hence are shared. By default, there will be a limit on the CPU time that can be used on a Login Node by a user and there is a limit/user on the memory as well. If any of these are exceeded, the job will get terminated.</p> Login Nodes: 10 2* Intel Xeon G-6240R  Cores = 48, 2.4 GHz Total Cores = 480 cores Memory= 192 GB each Total Memory = 1920 GB"},{"location":"Page2-SAAC/#service-nodes","title":"Service Nodes","text":"<p>PARAM Rudra is an aggregation of a large number of nodes connected through networks. Management nodes plays a crucial role in managing and monitoring every component of PARAM Rudra cluster. This includes monitoring the health, load, and utilization of individual components, as well as providing essential services such as security, management, and monitoring to ensure the cluster functions smoothly. </p> Management Nodes: 8 2* Intel Xeon G-6240R  Cores = 48, 2.4 GHz Total Cores = 96 cores Memory= 192 GB each Total Memory = 384 GB Visualization Nodes: 2 2* Intel Xeon G-6240R  Cores = 48, 2.4 GHz Total Cores = 96 cores Memory= 192 GB each Total Memory = 384 GB"},{"location":"Page2-SAAC/#cpu-compute-nodes","title":"CPU Compute Nodes","text":"<p>CPU nodes are the individual machines dedicated to performing computational tasks. These nodes collectively form the computational power of the cluster. All the CPU intensive activities are carried on these nodes. Users can access these nodes from the login node to run interactive or batch jobs. </p> CPU only Compute Nodes: 473 2* Intel Xeon G-6240R  Cores = 48, 2.4 GHz Total Cores = 22704 cores Memory= 192 GB each Total Memory = 90816 GB SSD 800 GB local per node"},{"location":"Page2-SAAC/#gpu-ready-compute-nodes","title":"GPU Ready Compute Nodes","text":"<p>GPU Ready Compute Nodes are similar to CPU Compute nodes which can be upgraded to support GPU computations in the future.</p> GPU Compute Nodes: 32 2* Intel Xeon G-6240R  Cores = 48, 2.4 GHz Total Cores = 1536 cores Memory= 192 GB each  , DDR4 2933 MHz Total Memory = 6144 GB SSD 800 GB (local) per node"},{"location":"Page2-SAAC/#gpu-compute-nodes","title":"GPU Compute Nodes","text":"<p>GPU Compute Nodes feature accelerators cards that offer significant acceleration for parallel computing tasks using frameworks like CUDA and OpenCL. By harnessing the computational power of modern GPUs, these nodes are utilized for tasks such as scientific simulations, deep learning, and data analytics, providing high computational power and memory.</p> GPU Compute Nodes: 30 2* Intel Xeon G-6240R  Cores = 48, 2.4 GHz Total Cores = 1440 cores Memory= 192 GB each  , DDR4 2933 MHz Total Memory = 5760 GB SSD 800 GB (local) per node 2Nvidia A100 per node GPU Cores per node= 26912= 13824 GPU Memory = 80 GB HBM2e per Nvidia A100"},{"location":"Page2-SAAC/#high-memory-compute-nodes","title":"High Memory Compute Nodes","text":"<p>High Memory Compute nodes are specialized nodes designed to handle workloads that require a large amount of memory.</p> High memory Compute Nodes: 64 2* Intel Xeon G-6240R  Cores = 48, 2.4 GHz Total Cores = 3072 cores Memory= 768 GB each  , DDR5 2933 MHz Total Memory = 49152 GB SSD 800 GB (local) per node"},{"location":"Page2-SAAC/#storage","title":"Storage","text":"<ul> <li>Based on Lustre parallel file system </li> <li>Total useable capacity of 4.4 PiB Primary Storage </li> <li>Throughput 100 GB/s</li> </ul>"},{"location":"Page2-SAAC/#param-rudra-architecture-diagram","title":"PARAM Rudra Architecture Diagram","text":"<p>Figure 1 - PARAM Rudra Architecture Diagram</p>"},{"location":"Page2-SAAC/#operating-system","title":"Operating System","text":"<p>The operating system on PARAM Rudra is Linux \u2013 Alma 8.7</p>"},{"location":"Page2-SAAC/#network-infrastructure","title":"Network infrastructure","text":"<p>A robust network infrastructure is essential for implementing the basic functionalities of a cluster. These functionalities include:</p> <ul> <li> <p>Management functionalities, such as monitoring, troubleshooting, starting and stopping various components of the cluster. The network/ or portion of the network that implements this functionality is referred to as the Management fabric.</p> </li> <li> <p>Ensuring fast read/ writes access to the storage, the network or portion of the network that implements this functionality is referred to as the storage fabric.</p> </li> <li> <p>Ensuring fast I/O operations, such as connecting to other clusters and connecting the cluster to various users on the campus LAN. The network or portion of the network that implements this functionality is referred to as the I/O Fabric.</p> </li> <li> <p>Ensuring High-Bandwidth, Low-latency communication among processors is essential for achieving high-scalability. The network or portion of the network that implements this functionality is referred to as Message Passing Fabric.</p> </li> </ul> <p>Technically, all the above functionalities can be implemented in a single network. However, for optimal performance, economic suitability, and meeting specific requirements, these functionalities are implemented using two different networks based on different technologies, as explained below:</p>"},{"location":"Page2-SAAC/#primary-interconnection-network","title":"Primary Interconnection Network","text":""},{"location":"Page2-SAAC/#infiniband-hdr-100-gbps","title":"InfiniBand: HDR 100 Gbps","text":"<p>Computing nodes of PARAM Rudra are interconnected by a high-bandwidth, low-latency interconnect network, specifically InfiniBand: HDR 100 Gbps. InfiniBand, a high-performance communication architecture owned by Mellanox, offers low communication latency, low power consumption and a high throughput. All CPU nodes are connected via the InfiniBand interconnect network.</p>"},{"location":"Page2-SAAC/#secondary-interconnection-network","title":"Secondary Interconnection Network","text":""},{"location":"Page2-SAAC/#gigabit-ethernet-10-gbps","title":"Gigabit Ethernet:  10 Gbps","text":"<p>Gigabit Ethernet is the most commonly available interconnection network. No additional modules or libraries are required for Gigabit Ethernet. Both Open MPI, MPICH implementations will work over Gigabit Ethernet. </p>"},{"location":"Page2-SAAC/#software-stack","title":"Software Stack","text":"<p>Software Stack is an aggregation of software components that work together to accomplish various task. These tasks can range from facilitating users in executing their jobs to enable system administrator to manage the system efficiently. Each software component within the stack is equipped with the necessary tools to achieve its specific task, and there may be multiple components of different flavors for different sub-tasks. Users have the flexibility to mix and match these components according to their preferences. For users, the primary focus is on preparing executables, executing them with their datasets, and visualizing the output. This typically involves compiling codes, linking them with communication libraries, math libraries, and numerical algorithm libraries, preparing executables, running them with desired datasets, monitoring job progress, collecting results, and visualizing output.</p> <p>System administrators, on the other hand, are concerned with ensuring optimal resource utilization. To achieve this, they may require installation tools, health-check tools for all components, efficient schedulers, and tools for resource allocation and usage monitoring.</p> <p>The software stack provided with this system have a wide range of software components that meet the needs of both users and administrators. Figure 2 illustrates the components of the software stack.</p> <p>C-CHAKSHU, a multi-cluster management tool designed to help administrator operate the HPC facility efficiently. It also enables the users to monitor system metrics relating to CPU, storage, interconnects, file system and application-specific utilization from a single dashboard. For more information, please follow the link: https://paramrudra.iuac.res.in/chakshu-front</p> <p></p> <p>Figure 2 - Software Stack</p> Functional Areas Components  Base OS Alma 8.7  Architecture X86_64  Provisioning and  Cluster Manager xCAT 2.16.5  Monitoring Tools C-CHAKSHU, Nagios, Ganglia  Resource Manager SLURM- 23.02.6  I/O Services Lustre Client  High Speed Interconnects Mellanox InfiniBand  (MLNX_OFED_LINUX-23.10)   Compiler Families GNU (gcc, g++, GNU Fortran)  Intel Compiler (icc, ifort, icpc)   MPI Families MVAPICH, Open MPI, MPICH"},{"location":"Page3-FTF/","title":"First Things First","text":""},{"location":"Page3-FTF/#getting-an-account-on-param-rudra","title":"Getting an Account on PARAM Rudra","text":"<p>To begin with, you need to get an account on PARAM Rudra.</p> <p>Recommended process for creating a user account to access the PARAM Rudra:</p> <ul> <li>Visit nsmindia.in</li> <li>Navigate to the \"How to access NSM HPC System\" section, where you will find a link to the User Creation portal.</li> <li>Click on the provided link to access the registration page.</li> <li>Fill in all required information on the registration page.</li> <li>Select IUAC, New Delhi as the institute.</li> <li>Upload the necessary documents as instructed.</li> <li>Once the form is complete, submit the details.</li> <li>The NSM committee will review the submission.</li> <li>If accepted, users will receive an email containing their user credentials and allocated cluster.</li> </ul>"},{"location":"Page4-HAC/","title":"How to access the cluster","text":"<p>To access cluster using Windows:</p> <p>To access PARAM Rudra, there are few tools available, please see some below:</p> <ul> <li> <p>PuTTY is the most popular open source ssh client application for Windows. Following are the steps:</p> </li> <li> <p>Download PuTTY from its official website.</p> </li> <li>Install PuTTY on your computer.</li> <li>Launch Putty from your desktop or Start menu.</li> <li>In the dialog, locate the \"Hostname or IP Address\" input field.</li> <li>Enter the hostname of the cluster: paramrudra@iuac.res.in</li> <li>For IUAC users, use port 22</li> <li>For external users, use port 4422</li> <li>Select open, then enter your username</li> <li>Enter the captcha when prompted, then input your password.</li> <li>Press Enter to proceed with the connection.</li> <li> <p>Another popular tool is MobaXterm, which is a third party freely available tool which can be used to access the HPC system and transfer files to the PARAM Rudra system through your local systems (laptop/desktop). Here are the steps:</p> </li> <li> <p>Download MobaXterm from its official website.</p> </li> <li>Install MobaXterm on your computer.</li> <li>Launch MobaXterm from your desktop or Start menu.</li> <li>Click on the \"Session\" button in MobaXterm.</li> <li>Enter the hostname, along with your username.</li> <li>For IUAC users, use port 22</li> <li>For external users, use port 4422</li> <li>Enter the captcha when prompted, then input your password.</li> <li>Press Enter to proceed with the connection.</li> </ul> <p></p> <p>Figure 3 - A snapshot of command using MobaXterm</p> <ul> <li>Command Prompt (Windows native application)</li> </ul> <p>This is a native tool for Windows machines which can be used to transfer data from the PARAM Rudra system through your local systems (laptop/desktop).</p> <p></p> <p>Figure 4 - A snapshot of the \"scp\" command using Windows command prompt.</p> <ul> <li>PowerShell (Windows native application)</li> </ul> <p>This is a native tool for Windows machines which could be used to transfer data from the PARAM Rudra system through your local systems (laptop/desktop).</p> <p></p> <p>Figure 5 - A snapshot of the \"scp\u201d command using Windows PowerShell.</p> <p>To access cluster using Mac or Linux</p> <p>Both Mac and Linux systems provide a built-in SSH client, eliminating the need to install any additional package. To connect to a SSH server, open the terminal and type the following command:</p> <p>ssh[username]@[hostname]</p> <p>For example, to connect to PARAM Rudra cluster: For IUAC Users:</p> <pre><code>user1@paramrudra.iuac.res.in\n</code></pre> <p>For External Users:</p> <pre><code>user1@paramrudra.iuac.res.in -p 4422\n</code></pre> <p>After entering captcha, you will be prompted for a password. Once entered, you will be connected to the server.</p> <p>After getting credentials you may access the cluster, please remember the following points:</p> <ul> <li>When you log in to the cluster, you will land on the login nodes. The login node serves as the primary gateway to the rest of the cluster, housing a job scheduler (known called Slurm) and other applications for creating and submitting the job. You can submit jobs to the queue, and they will execute when the required resources become available.</li> <li>Please refrain from running jobs directly on the login node. Login nodes are intended for compiling codes, transferring data and submitting jobs. If you run your job directly on the login node, it will be terminated.</li> <li>By default, two directories are available (i.e. /home and /scratch). These directories are available on the login node as well as the other nodes on the cluster. /scratch is for temporary data storage, generally used to store data required for running jobs. Users are requested to regularly back up their own data in scratch directory. As per policy, any files not accessed in the last three months will be permanently deleted.</li> </ul>"},{"location":"Page4-HAC/#first-login","title":"First login","text":"<p>Whenever a newly created user on PARAM Rudra attempts to log in with the user ID and temporary password provided via email by PARAM Rudra support, it is mandatory for the user to change the password to one of their choosing. This ensures the security of your account. It is recommended to use a strong password containing a combination of lowercase and uppercase letters, numbers, and a few special characters that are easy for you to remember.</p> <p>Your password will be valid for 90 days. On expiry of 90 days period, you will be prompted to change your password, on attempting to log in. You are required to provide a new password.</p>"},{"location":"Page4-HAC/#forgot-password","title":"Forgot Password?","text":"<ol> <li>Please open a ticket regarding this issue, and the support team will assist you with your problem. Follow the steps below:</li> <li>Visit the PARAM Rudra support site, which is the ticketing tool, by clicking on the following link: PARAM Rudra Support.</li> <li>Log in using your username or registered email ID.</li> <li>Raise a ticket to request a password reset.</li> <li>The support team will respond with an email for verification.</li> <li>Once you acknowledge the email, the password will be reset for you, and you will receive an email confirming the same.</li> <li>You can then log in using the temporary password provided and set a new password of your choice.</li> </ol>"},{"location":"Page4-HAC/#how-to-change-the-password","title":"How to change the password:","text":"<p>Use the passwd command to change your user password. Enter your current password, followed by your new password, and then confirm the new password.</p>"},{"location":"Page5-TF-HPC/","title":"Transferring files between local machine and HPC cluster","text":"<p>Users need to have the their data and applications related to their project or research work on PARAM Rudra. To store the data, special directories named \u201chome\u201d have been made available to the users. While these directories are common to all the users, each user will have their own directory with their username in the \u201c/home/\u201d directory, where they can store their data.</p> <p>/home/<code>&lt;username&gt;</code>/ : This directory is generally used by the user to store their data and if need install their own applications.</p> <p>However, there is a limit to the storage provided to users. The limits have been defined according to quota over these directories, and all users will be allotted the same quota by default. When a user wishes to transfer data from their local system (laptop/desktop) to the HPC system, they can use various methods and tools.</p> <p>A user using the \u2018Windows\u2019 operating system will have access to methods and tools native to Microsoft Windows, as well as tools that can be installed on their Windows machine. Linux operating system users, however, do not require any tool. They can simply use the \u201cscp\u201d command on their terminal. Here\u2019s how:</p> <pre><code>scp -r -P 22 &lt;path to the local data directory&gt; \n&lt;username&gt;@paramrudra.iuac.res.in:&lt;path to directory on HPC where to save \nthe data&gt;\n</code></pre> <p>Note</p> <p>Note: use port 22 within IUAC Institute</p> <p>Example:</p> <p>Same Command could be used to transfer data from the HPC system to other HPC system, or your own system.</p> <pre><code>scp -r -P 4422 &lt;file path&gt; &lt;username@&lt;cluster IP/hostname&gt;:/home/user/&lt;path&gt;\n</code></pre> <p>Note</p> <p>Use port 22 within IUAC Institute</p> <p> The local system (laptop/desktop) must be connected to a network that allows access to the HPC system. Additionally, please ensure that the firewall settings on your laptop are configured to allow access from the HPC system. </p> <p>Users are advised to keep a copy of their data once their project or research work is completed by transferring the data from PARAM Rudra to their local system (laptop/desktop). The command below can be used for file transfers in all the tools.</p>"},{"location":"Page5-TF-HPC/#tools","title":"Tools","text":"<p><code>&lt;b style=\"color:#259AA4\"&gt;</code>WinSCP (Windows installable application)<code>&lt;/b&gt;</code></p> <p>This popular tool is freely available and is used very often to transfer data from Windows machine to Linux machine. This tool is GUI based which makes it very user-friendly.</p> <p>Link for this tool is: https://winscp.net/eng/download.php</p> <p></p> <p>Figure 6 - A snapshot of the \"WinSCP\" tool to transfer file to and from remote computer.</p> <p></p> <p>Figure 7\u2013Enter Captcha/String</p> <p>Note</p> <p> Port Used for SFTP connection is 4422 and not 22. Please change it to 4422 </p>"},{"location":"Page6-ResourceM/","title":"Resource Management","text":"<p>This section explains how you interact with the resource manager. It covers information about the resource manager, the definition of nodes within partitions, job policies, scheduler information, the process of submitting jobs to the cluster, monitoring active jobs and getting useful information about resource usage.</p> <p>A cluster is a group of computers that work together to solve complex computational tasks and presents itself to the user as a single system. For the resources of a cluster (e.g. CPUs, GPUs, memory) to be used efficiently, a resource manager (also called workload manager or batch-queuing system) is important. While there are many different resource managers available, the resource manager at PARAM Rudra is SLURM. After submitting a job to the cluster, SLURM will try to fulfill the job\u2019s resource request by allocating resources to the job. If the requested resources are already available, the job can start immediately. Otherwise, the start of the job is delayed (pending) until enough resources are available. SLURM allows you to monitor active (pending, running) jobs and to retrieve statistics about finished jobs. </p> <p>SLURM, which is open-source workload manager, efficiently allocates computing resources such as CPUs, GPUs, and memory to users' jobs, ensuring optimal resource utilization and job scheduling. SLURM provides features for job submission, monitoring, and management, allowing users to specify job requirements and dependencies. Slurm is a widely used batch scheduler in the top500 HPC list.</p>"},{"location":"Page6-ResourceM/#slurm-partitions","title":"SLURM Partitions","text":"<p>Partition is a logical grouping of nodes that share similar characteristics or resources. Partitions are helpful to manage and allocate resources efficiently based on the specific requirements of jobs or users. PARAM Rudra consists of three types of computational nodes: i.e. CPU only nodes, High memory (with 768 GB memory) nodes and GPU-enabled GPGPU nodes. The following partitions/queues have been defined to meet different user requirements:</p> <ul> <li>standard: By default, All user job will be submitted to the standard partition which contains 569 nodes. These nodes consist of CPU and High Memory (HM) nodes.</li> <li>CPU: This partition is specifically designed for nodes that only have CPU resources.</li> <li>GPU: The GPU partition includes nodes equipped with NVIDIA A100 GPUs. Jobs submitted to this partition will run on nodes that can leverage the high-performance computing capabilities of A100 GPU cards for parallel processing tasks.  The GPU partition exclusively contains GPU nodes. If a user\u2019s wishes to submit a job only on GPU nodes, they need to specify the number of GPU cards with the partition name.</li> <li>hm: The High Memory partition is intended for nodes with a substantial amount of RAM. Specifically, it accommodates CPU nodes that are equipped with 768 GB of RAM, allowing jobs requiring large memory resources to be executed efficiently.</li> </ul>"},{"location":"Page6-ResourceM/#qos-job-policy","title":"QoS Job policy","text":"<p>Users have the flexibility to run up to 10 simultaneous jobs. They can run an 8-node job for 4 days, a 16-node job for 2 days, or a 32-node job for 1 day. The default policy of the cluster allows for a maximum wall time of 4 days per job. However, this policy can be tailored to individual user needs or adjusted for all users in the future, depending on cluster usage. Users will be informed about any changes made to the SLURM policy.</p> <p>Walltime</p> <p>The walltime parameter defines how long your job will run, with the maximum runtime determined by the QoS Policy. The default walltime for every job is 2 hours, so users are requested to explicitly specify the walltime in their scripts. If more than 4 days are required, users can raise a query on the support portal of PARAM Rudra, and it will be addressed on a case-by-case basis. If a job exceeds the specified walltime in the script, it will be terminated. Specifying the appropriate walltime improves scheduling efficiency, resulting in enhanced throughput for all jobs, including yours.</p>"},{"location":"Page6-ResourceM/#scheduling-type","title":"Scheduling Type","text":"<p>PARAM Rudra has been configured with Slurm\u2019s backfill scheduling policy. It is good for ensuring higher system utilization; it will start lower priority jobs if doing so does not delay the expected start time of any higher priority jobs. Since the expected start time of pending jobs depends upon the expected completion time of running jobs, reasonably accurate time limits are important for backfill scheduling to work well.</p> <p>Job Priority</p> <p>The job's priority at any given time will be a weighted sum of all the factors that have been enabled in the slurm.conf file. Job priority can be expressed as:</p> <pre><code>Job_priority =\n    site_factor +\n    (PriorityWeightAge) * (age_factor) +\n    (PriorityWeightAssoc) * (assoc_factor) +\n    (PriorityWeightFairshare) * (fair-share_factor) +\n    (PriorityWeightJobSize) * (job_size_factor) +\n    (PriorityWeightPartition) * (priority_job_factor) +\n    (PriorityWeightQOS) * (QOS_factor) +\n    SUM(TRES_weight_cpu * TRES_factor_cpu,\n        TRES_weight_&lt;type&gt; * TRES_factor_&lt;type&gt;,\n        ...)\n    - nice_factor\n</code></pre> <p>All of the factors in this formula are floating point numbers that range from 0.0 to 1.0. The weights are unsigned, 32-bit integers. The larger the number, the higher the job will be positioned in the queue, and the sooner the job will be scheduled. A job's priority, and hence its order in the queue, can vary over time. For example, the longer a job sits in the queue, the higher its priority will grow when the age weight is non-zero.</p> <p>Age Factor: The age factor represents the length of time a job has been sitting in the queue and eligible to run. </p> <p>Association Factor: Each association can be assigned an integer priority. The larger the number, the greater the job priority will be for jobs that request this association. This priority value is normalized to the highest priority of all the association to become the association factor.</p> <p>Job Size Factor: The job size factor correlates to the number of nodes or CPUs the job has requested. </p> <p>Nice Factor: Users can adjust the priority of their own jobs by setting the nice value on their jobs. Like the system nice, positive values negatively impact a job's priority and negative values increase a job's priority. Only privileged users can specify a negative value. </p> <p>Partition Factor: Each node partition can be assigned an integer priority. The larger the number, the greater the job priority will be for jobs that request to run in this partition. </p> <p>Quality of Service (QOS) Factor: Each QOS can be assigned an integer priority. The larger the number, the greater the job priority will be for jobs that request this QOS. </p> <p>Fair-share Factor: The fair-share component to a job's priority influences the order in which a user's queued jobs are scheduled to run based on the portion of the computing resources they have been allocated and the resources their jobs have already consumed. </p>"},{"location":"Page6-ResourceM/#job-submission","title":"Job Submission","text":"<p>We can submit jobs either through a SLURM script or by using the interactive method. Creating a SLURM script is the optimal way to submit a job to the cluster.</p> <p>Submitting Batch Scripts Jobs</p> <p>Here is the example of sample slurm script:</p> <pre><code>#!/bin/bash#!/bin/bash\n#SBATCH -N 1            // number of nodes\n#SBATCH --ntasks-per-node=1     // number of cores per node\n#SBATCH --error=job.%J.err  // name of output file\n#SBATCH --output=job.%J.out     // name of error file\n#SBATCH --time=01:00:00     // time required to execute the program\n#SBATCH --partition=standard // specifies queue name (standard is the default partition if you do not specify any partition job will be submitted using default partition). For other partitions you can specify hm or gpu\n\n\n// To load the package //\nspack load intel-oneapi-compilers\n\ncd  &lt;Path of the executable&gt;\na.out  (Name of the executable)\n</code></pre> <p>We can consider four cases of submitting a job here:</p> <ul> <li>Submitting a simple standalone job</li> </ul> <p>This is a simple submit script which is to be submitted</p> <pre><code>$ sbatch slurm-job.sh\n</code></pre> <p>Submitted batch job 106</p> <ul> <li>Submit a job\u00a0that's dependent on a prerequisite job being completed</li> </ul> <p>Consider a requirement of pre-processing a job before proceeding to actual processing. Pre-processing is generally done on a single core. In this scenario, the actual processing script is dependent on the outcome of the pre-processing script. Here\u2019s a simple job script.</p> <p>Note that the Slurm -J option is used to give the job a name.</p> <pre><code>#!/bin/bash\n#SBATCH -p standard\n#SBATCH -J simple\nsleep 60\n\n\n\nSubmit the job:  \n$ sbatch simple.sh\nSubmitted batch job 149\n</code></pre> <p>Now we'll submit another job that's dependent on the previous job. There are many ways to specify the dependency conditions, but the \"singleton\" method is the simplest. The Slurm -d singleton argument tells Slurm not to dispatch this job until all previous jobs with the same name have completed.</p> <pre><code>$ sbatch -d singleton simple.sh //may be used for first pre-processing on a core and then submitting\nSubmitted batch job 150\n\n$ squeue\n\u00a0 JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON)\n\u00a0\u00a0\u00a0 150 standard\u00a0\u00a0 simple user1\u00a0 PD\u00a0 0:00\u00a0 1 (Dependency)\n\u00a0\u00a0\u00a0 149 standard\u00a0\u00a0 simple\u00a0 user1\u00a0\u00a0 R\u00a0  0:17\u00a0 1 rpcn001\n</code></pre> <p>Once the prerequisite job finishes the dependent job is dispatched.</p> <pre><code>$ squeue\n\u00a0 JOBID PARTITION  NAME    USER   ST   TIME\u00a0 NODES NODELIST(REASON)\n\u00a0\u00a0\u00a0 150 standard\u00a0\u00a0 simple\u00a0 user1\u00a0\u00a0 R\u00a0\u00a0 0:31\u00a0     1 rpcn001\n</code></pre> <ul> <li>Submit a job with a reservation allocated Slurm has the ability to reserve resources for jobs being executed by select users and/or select bank accounts. A resource reservation identifies the resources in that reservation and a time period during which the reservation is available. The resources which can be reserved include cores, nodes.</li> </ul> <p>Use the  command given below to check the reservation name allocated to your user account</p> <pre><code>$ scontrol show reservation\n</code></pre> <p>If your \u2018user account\u2019 is associated with any reservation the above command will show you the same. For e.g. The given reservation name is user_11. Use the command given below to make use of this reservation</p> <pre><code>$ sbatch --reservation=user_11 simple.sh\n</code></pre> <ul> <li>Submitting multiple jobs with minor or no changes (array jobs)</li> </ul> <p>A\u00a0SLURM job array\u00a0is a collection of\u00a0jobs\u00a0that differs from each other by only a single index parameter. Job arrays can be used to submit and manage a large number of jobs with similar settings.</p> <p></p> <p>Figure 9 \u2013 Snapshot depicting the usage of \u201cJob Array\u201d</p> <p>N1 is specifying the number of nodes you want to use for your job. example: N1 -one node, N4 - four nodes. Instead of tmp here you can use the below example script.</p> <pre><code>#!/bin/bash\n#SBATCH -N 1\n#SBATCH --ntasks-per-node=48\n#SBATCH --error=job.%A_%a.err\n#SBATCH --output=job.%A_%a.out\n#SBATCH --time=01:00:00\n#SBATCH --partition=standard\n\nspack load intel-oneapi-compilers\ncd /home/guest/Rajneesh/Rajneesh    #change to your required directory\nexport OMP_NUM_THREADS=${SLURM_ARRAY_TASK_ID}\n/home/guest/Rajneesh/Rajneesh/md_omp\n</code></pre> <p>Running Interactive Jobs</p> <p>Another way to run your job is interactively. You can run an interactive job as follows:</p> <p>The following command asks for a single core in one hour with default amount of memory. </p> <pre><code>$ srun --nodes=1 --ntasks-per-node=1 --time=01:00:00 --pty /bin/bash -i\n</code></pre> <p>The command prompt of the allocated compute node will appear as soon as the job starts. </p> <p>Exit the bash shell to end the job. </p> <p>If the job is waiting for the resources, then this is how it will look :</p> <pre><code>$ job 1040 queued and waiting for resources\n</code></pre> <p>If after a while, it will allocate resources, then it will look like this:</p> <pre><code>$ job 1040 has been allocated resources\n</code></pre> <p>If you exceed the time or memory limit the job will also abort.</p> <p>Please note that PARAM Rudra is NOT meant for executing interactive jobs. However, it can be utilized to quickly verify the successful execution of a job before submitting a larger batch job with a high iteration count. It can also be used for running small jobs. However, it's important to consider that other users may also be utilizing this node, so it's advisable not to inconvenience them by running large jobs. </p> <p>There are various use cases for requesting interactive resources, such as debugging (launching a job, adjusting setup parameters like compile options, relaunching the job, and making further adjustments) and interactive interfaces (inspecting a node, etc.).</p> <p>Parameters used in SLURM job script</p> <p>The job flags are used with the SBATCH command. \u00a0The syntax for the SLURM directive in a script is\u00a0\"#SBATCH \". \u00a0Some of the flags are used with the srun and salloc commands. Flag Syntax Description partition --partition= Partition is a queue for the jobs. time --time=01:00:00 Time limit for the job. nodes --nodes=2 Number of compute nodes for the job. cpus/cores --ntasks-per-node=8 Corresponds to the number of cores on the compute node. resource feature --gres=gpu:2 Request use of GPUs on the gpu compute nodes account --account= User may belong to multiple accounts. If only one account is allocated, it will be set as the default. job name --job-name=\"lammps\" Name of the job. error file --error= Instruct Slurm to connect the batch script's standard error directly to the file name specified in the \"filename pattern\". By default both standard output and standard error are directed to the same file. output file --output= Instruct Slurm to connect the batch script's standard output directly to the file name specified in the \"filename pattern\". By default both standard output and standard error are directed to the same file. node list -w, --nodelist Request a specific list of hosts. mail-type --mail-type= Notify users by email when certain event types occur. Valid type values are NONE, BEGIN, END, FAIL, REQUEUE, ALL, TIME_LIMIT, TIME_LIMIT_90 (reached 90 percent of time limit), TIME_LIMIT_80 (reached 80 percent of time limit), and TIME_LIMIT_50 (reached 50 percent of time limit), and ARRAY_TASKS (send emails for each array task). Multiple type values may be specified in a comma separated list mail-user --mail-user= User to receive email notification of state changes as defined by --mail-type. Reservation --reservation= Allocate resources for the job from the named reservation. Validate script --test-only Validate the batch script and return an estimate of when a job would be scheduled to run given the current job queue and all the other arguments specifying the job requirements. No job is actually submitted. exclusive access to nodes --exclusive Exclusive access to compute nodes.The job allocation cannot share nodes with other running jobs"},{"location":"Page6-ResourceM/#sample-slurm-scripts-for-reference","title":"<p>Sample SLURM Scripts for reference</p>","text":"<p>Script for a Sequential Job</p> <pre><code>#!/bin/bash\n#SBATCH -N 1   // number of nodes\n#SBATCH --ntasks-per-node=1 // number of cores per node\n#SBATCH --error=job.%J.err // name of output file\n#SBATCH --output=job.%J.out // name of error file\n#SBATCH --time=01:00:00    // time required to execute the program\n#SBATCH --partition=standard // specifies queue name (standard is the default partition if you do not specify any partition job will be submitted using default partition). For other partitions you can specify hm or gpu\n\n\n// To load the package //\nspack load intel-oneapi-compilers\n\ncd  &lt;Path of the executable&gt;\na.out  (Name of the executable)\n</code></pre> <p>Script for a Parallel OpenMP Job</p> <pre><code>#!/bin/bash\n#SBATCH -N 1                  // Number of nodes\n#SBATCH --ntasks-per-node=48  // Number of core per node\n#SBATCH --error=job.%J.err    // Name of output file\n#SBATCH --output=job.%J.out   // Name of error file\n#SBATCH --time=01:00:00       // Time take to execute the program \n#SBATCH --partition=cpu       // specifies partition name\n\n\nspack load intel-oneapi-compilers  // To load the package\n\ncd  &lt;path of the executable&gt;\nor \ncd  $SLURM_SUBMIT_DIR //To run job in the directory from where it is submitted\n\nexport OMP_NUM_THREADS=48 //Depending upon your requirement you can change the number of threads. If total number of threads per node is more than 48, multiple threads will share core(s) and performance may degrade)\n\n/home/cdac/a.out       //Name of the executable)\n</code></pre> <p>Script for Parallel Job \u2013 MPI (Message Passing Interface)</p> <pre><code>#!/bin/sh\n\n#SBATCH -N 16                           // Number of nodes\n#SBATCH --ntasks-per-node=48            // Number of cores per node\n#SBATCH --time=06:50:20                 // Time required to execute the program\n#SBATCH --job-name=lammps               // Name of application\n#SBATCH --error=job.%J.err_16_node_48     // Name of the output file\n#SBATCH --output=job.%J.out_16_node_48    // Name of the error file\n#SBATCH --partition=standard              // Partition or queue name\nspack load intel-oneapi-compilers       // To load the package\n\n\n// Below are Intel MPI specific settings //\n\nexport I_MPI_FALLBACK=disable\nexport I_MPI_FABRICS=shm:dapl  \nexport I_MPI_DEBUG=9                // Level of MPI verbosity\n\ncd $SLURM_SUBMIT_DIR    //change to required path where command needs to be executed\nor \ncd /home/manjuv/LAMMPS_2018COMPILER/lammps-22Aug18/bench\n\n// Example Command to run the lammps in Parallel // \n\ntime mpiexec.hydra -n $SLURM_NTASKS -genv OMP_NUM_THREADS 1 /home/manjuv/LAMMPS_2018COMPILER/lammps-22Aug18/src/lmp_intel_cpu_intelmpi -in in.lj\n</code></pre> <p>Script for Hybrid Parallel Job \u2013 (MPI + OpenMP)</p> <pre><code>#!/bin/sh\n\n#SBATCH -N 16               // Number of nodes\n#SBATCH --ntasks-per-node=48    // Number of cores for node\n#SBATCH --time=06:50:20         // Time required to execute the program\n#SBATCH --job-name=lammps       // Name of application\n#SBATCH --error=job.%J.err_16_node_48  // Name of the output file\n#SBATCH --output=job.%J.out_16_node_48 // Name of the error file\n#SBATCH --partition=standard           // Partition or queue name \n\nspack load intel-oneapi-compilers       // To load the package\n//change to script submission directory\ncd $SLURM_SUBMIT_DIR\n\n// Below are Intel MPI specific settings //\nexport I_MPI_FALLBACK=disable\n\nexport I_MPI_FABRICS=shm:dapl  \nexport I_MPI_DEBUG=9                // Level of MPI verbosity \nexport OMP_NUM_THREADS=24 //Possibly then total no. of MPI ranks will be = (total no. of cores, in this case 16 nodes x 48 cores/node) divided by (no. of threads per MPI rank i.e. 24)\n// Example Command to run the lammps in Parallel // \ntime mpiexec.hydra  -n 32 lammps.exe -in in.lj\n</code></pre> <p></p>"},{"location":"Page6-ResourceM/#listing-partition","title":"Listing Partition","text":"<p>sinfo displays information about nodes and partition allowing users to view available nodes in the partition within the cluster.</p> <p></p> <p>Figure 8- Output of sinfo command</p>"},{"location":"Page6-ResourceM/#monitoring-jobs","title":"Monitoring jobs","text":"<p>Monitoring jobs on SLURM can be done using the command\u00a0squeue.\u00a0 The command squeue provides high-level information about jobs in the Slurm scheduling queue (state information, allocated resources, runtime, etc .</p> <pre><code>$ squeue\n\u00a0 JOBID PARTITION  NAME      USER    ST  TIME  NODES  NODELIST(REASON)\n\u00a0\u00a0\u00a0106  standard\u00a0\u00a0\u00a0 slurm-jo\u00a0     user1\u00a0\u00a0   R\u00a0\u00a0  0:04\u00a0\u00a0\u00a0\u00a0\u00a0 1     rpcn001\n</code></pre> <p>The command scontrol provides even more detailed information about jobs and job steps. It will report more detailed information about nodes, partitions, jobs, job steps, and configuration. </p> <pre><code>$ scontrol show job &lt;jobid&gt;\n</code></pre> <p></p> <p>Figure 12 \u2013 scontrol show job displays specific job information</p> <pre><code>scontrol update job\u00a0&lt;jobid&gt;- set &lt;new attribute value&gt;\n</code></pre> <p>The above command change attributes of submitted job. Like time limit, nodelist, number of nodes, etc. For example:</p> <pre><code>scontrol update jobid=106 set TimeLimit=4-00:00:00\n</code></pre>"},{"location":"Page6-ResourceM/#deleting-jobs","title":"Deleting jobs:","text":"<p>Use the scancel command to delete active jobs. Users can cancel their own jobs only.</p> <pre><code>$ scancel &lt;jobid&gt;\n$ scancel 135\n$ squeue --me\n\u00a0 JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON)\n</code></pre> <p>Holding a job:</p> <p>Use the scontrol command to hold the job.</p> <pre><code>$scontrol hold &lt;jobid&gt;\n$ squeue\n\u00a0 JOBID PARTITION\u00a0\u00a0NAME\u00a0\u00a0\u00a0\u00a0USER\u00a0  ST\u00a0\u00a0\u00a0\u00a0\u00a0 TIME\u00a0 NODES NODELIST(REASON)\n\u00a0\u00a0\u00a0 139\u00a0standard\u00a0\u00a0 simple\u00a0 user1\u00a0 PD\u00a0\u00a0\u00a0\u00a0\u00a0 0:00\u00a0\u00a0\u00a0\u00a0\u00a0 1 (Dependency)\n138\u00a0standard\u00a0\u00a0 simple\u00a0 user1\u00a0\u00a0 R\u00a0\u00a0\u00a0\u00a0\u00a0 0:16\u00a0\u00a0\u00a0\u00a0\u00a0 1  rpcn001\n\n$ scontrol hold 139\n$ squeue\n\u00a0 JOBID PARTITION\u00a0\u00a0NAME\u00a0\u00a0\u00a0\u00a0USER\u00a0  ST\u00a0\u00a0\u00a0\u00a0 TIME\u00a0 NODES NODELIST(REASON)\n\u00a0\u00a0\u00a0 139\u00a0standard\u00a0\u00a0 simple\u00a0 user1\u00a0 PD\u00a0\u00a0\u00a0\u00a0 0:00\u00a0\u00a0\u00a0\u00a0\u00a0 1 (JobHeldUser)\n\u00a0\u00a0\u00a0 138\u00a0standard\u00a0\u00a0 simple\u00a0 user1\u00a0\u00a0 R\u00a0\u00a0\u00a0  0:32\u00a0\u00a0\u00a0\u00a0\u00a0 1 rpcn001\n</code></pre> <p>Releasing a job:</p> <pre><code>$ scontrol release 139\n$ squeue\n\u00a0 JOBID PARTITION\u00a0\u00a0NAME\u00a0\u00a0\u00a0\u00a0 USER\u00a0 ST\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 TIME\u00a0 NODES NODELIST(REASON)\n\u00a0\u00a0\u00a0 139\u00a0standard\u00a0\u00a0 simple\u00a0 user1\u00a0 PD\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0:00\u00a0\u00a0\u00a0\u00a0\u00a0 1 (Dependency)\n\u00a0\u00a0\u00a0 138\u00a0standard\u00a0\u00a0 simple\u00a0 user1\u00a0\u00a0 R\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0:46\u00a0\u00a0\u00a0\u00a0\u00a0 1 rpcn001\n</code></pre>"},{"location":"Page6-ResourceM/#getting-node-and-partition-details","title":"Getting Node and Partition details","text":"<pre><code>scontrol show node\u00a0&lt;node\u00a0name&gt;\u00a0- shows detailed information about compute nodes.\n</code></pre> <p>Figure 10 \u2013 scontrol show node displays compute node information</p> <pre><code>scontrol show partition\u00a0&lt;partition\u00a0name&gt;- shows detailed information about a specific partition\n</code></pre> <p></p> <p>Figure 11 \u2013 scontrol show partition displays specific partition details</p>"},{"location":"Page6-ResourceM/#accounting","title":"Accounting","text":"<p>Accounting system tracks and manages HPC resource usage. As jobs are completed or resources are utilized, accounts are charged and resource usage is recorded. Accounting policy is like a Banking System, where each department can be allocated with some predefined budget on a quarterly basis for CPU usage. As and when the resources are utilized, the amount will be deducted. The allocation will be reset half yearly. Depending upon the policy, users will be informed when their account is created about how much CPU hours have been allocated to them.</p> <p>sacct</p> <p>This command can report resource usage for running or terminated jobs including individual tasks, which can be useful to detect load imbalance between the tasks. </p> <pre><code>$ sacct -j &lt;jobid&gt;\n</code></pre>"},{"location":"Page6-ResourceM/#investigating-a-job-failure","title":"Investigating a job failure","text":"<p>Job executions aren't always successful. There are various reasons for a job to stop or crash. The most common causes are:</p> <ul> <li>Exceeding resource limits</li> <li>Software-specific errors</li> </ul> <p>This section discusses methods to gather information and find ways to avoid common issues.</p> <p>It is important to collect error and output messages by either writing this information to the default location or specifying specific locations using the --error/--output option.  Redirecting the error/output stream to /dev/null should be avoided unless you fully understand its implications, as error and output messages serve as the initial point for investigating job failures.</p> <p>Exceeding Resource Limits</p> <p>Each partition defines default and maximum time limits of the job runtime and memory usage. Within the job script, the current limits can be defined within the ranges. For better scheduling, the job requirements should be estimated and the limits should be adapted to the needs. Lower limits enable SLURM to find suitable scheduling opportunities more effectively. Additionally, specifying minimal resource overhead minimizes resource wastage.</p> <p>If a job exceeds the runtime or memory limit, it will get killed by SLURM.</p> <p>Software Errors</p> <p>The exit code of a job is captured by Slurm and saved as part of the job record. For sbatch jobs the exit code of the batch script is captured. For srun, the exit code will be the return value of the executed command. Any non-zero exit code is considered a job failure, and results in job state of FAILED. When a signal was responsible for a job/step termination, the signal number will also be captured, and displayed after the exit code (separated by a colon).</p>"},{"location":"Page6-ResourceM/#i-am-familiar-with-pbs-torque-how-do-i-migrate-to-slurm","title":"I am familiar with PBS/ TORQUE. How do I migrate to SLURM?","text":"Environment Variables PBS/Torque SLURM Job Id $PBS_JOBID $SLURM_JOBID Submit Directory $PBS_JOBID $SLURM_SUBMIT_DIR Node List $PBS_NODEFILE $SLURM_JOB_NODELIST Job Specification PBS/Torque SLURM Script directive #PBS #BATCH Job Name -N [name] --job-name=[name] OR -J [name] Node Count -1 nodes=[count] --nodes=[min[-max]] OR -N [min[-max]] CPU count -1 ppn=[count] ---ntasks-per-node=[count] CPUs Per Task --cpus-per-task=[count] Memory Size -1 mem-[MB] --mem=[MB] OR \u2013mem_per_cpu=[MB] Wall Clock Limit -1 walltime=[hh:mm:ss] --time=[min] OR \u2013mem_per_cpu=[MB] Node Properties -1 nodes=4.ppn=8:[property] --constraint=[list] Standard Output File -o [file_name] --output=[file_name] OR -o [file_name] Standard Error File -e [file_name] --error=[file_name] OR -e {file_name] Combine stdout/stderr -j oe (both to stdout) (This is default if you do not specify \u2013error) Job Arrays -t [array_spec] --array=[array_spec] OR -a [array_spec] Delay Job Start -a [time] --begin=[time]"},{"location":"Page6-ResourceM/#addressing-basic-security-concerns","title":"Addressing Basic Security Concerns","text":"<ul> <li>Your account on PARAM Rudra is \u2018private to you\u2019. You are responsible for any actions emanating from your account. It is suggested that you should never share the password with anyone.</li> <li>Do not grant permission of your home directory to any other user, as it may expose your personal files to unauthorized access. Per user</li> <li>Every user will have quota of 50 GB of soft limit and X GB of hard limit with grace period of X days in HOME file system (/home) and X GB of soft limit and X GB of hard limit with grace period of X days in SCRATCH file system</li> <li>Users are recommended to copy their execution environment and input files to scratch file system (/scratch/) during job running and copy output data back to HOME area <li>File retention policy has been implemented on Lustre storage for the \"/scratch\" file system. As per the policy, any files that have not been accessed for the last 3 months will be deleted permanently</li> <p>It is important to note:</p> <ul> <li>Compilations are performed on the login node. Only the execution is scheduled via SLURM on the compute nodes.</li> <li>It is important to collect error/output messages, either by writing such information to the default location or by specifying specific locations using the --error or --output option. Error and output messages serves as the starting point for investigating a job failures. If not specified, the Job Id is also appended to the output and error filenames.</li> <li>Submitting a series of jobs (a collection of similar jobs) as array jobs instead of one by one is crucial for improving backfilling performance and thus job throughput, instead of submitting the same job repeatedly.</li> <li>User has to specify #SBATCH --gres=gpu:1/2 in their job script if user wants to use 1 or 2 GPU cards on GPU nodes</li> </ul>"},{"location":"Page7-LoadingM/","title":"Loading packages through SPACK","text":"<p>PARAM Rudra extensively uses spack. The purpose of spack is to provide freedom to users for loading required applications or packages of specific versions with all its dependencies in the user environment. Users can find the list of all installed packages with their specific versions and dependencies. This also specifies which version of the application is available for a given session. All applications and libraries are made available through spack. A User has to load the appropriate package from the available packages.</p>"},{"location":"Page7-LoadingM/#introduction","title":"Introduction","text":"<p>Spack automates the download-build-install process for software - including dependencies - and provides convenient management of versions and build configurations. It is designed to support multiple versions and configurations of software on a wide variety of platforms and environments. It is designed for large supercomputing centers, where many users and application teams share common installations of software on clusters with exotic architectures, using libraries that do not have a standard ABI. Spack is non-destructive: installing a new version does not break existing installations, so many configurations can coexist on the same system.</p> <p>On your login node command prompt execute below commands:</p> <pre><code>$ module load spack \n</code></pre> <p>It will load SPACK module and set up environment for SPACK.</p> <p></p> <p>Kindly see the above screenshot and source below line including initial dot.</p> <pre><code>$ . /home/apps/SPACK/spack/share/spack/setup-env.sh\n</code></pre>"},{"location":"Page7-LoadingM/#to-use-pre-installed-applications-from-spack","title":"To Use Pre-Installed Applications from Spack","text":"<p>spack find</p> <p>The spack find command is used to query installed packages on PARAM Kamrupa. Note that some packages appear identical with the default output. The -l flag shows the hash of each package, and the -f flag shows any non-empty compiler flags of those packages.</p> <p></p> <p>spack load application name</p> <p>The easiest way is to use spack load  <p></p> <p>To know the Pre-Loaded Application/Compliers</p>"},{"location":"Page7-LoadingM/#to-install-new-application","title":"To install new application","text":"<p>First check the available compilers in Spack with below command:</p> <p>spack compilers</p> <p>Spack manages a list of available compilers on the system, detected automatically from the user\u2019s PATH variable. The spack compilers command is an alias for the command spack compiler list.</p> <p></p> <p>To check the compliers available in the system</p> <p>Check if application is available in Spack repo with command-</p> <p>spack list</p> <p>The spack list command shows available packages.</p> <p>The spack list command can also take a query string. Spack automatically adds wildcards to both ends of the string, or you can add your own wildcards.</p> <p></p> <p>Before installing application check its spec with command</p> <p>spack install</p> <p>Below is an example of installation of package using spack:</p> <pre><code>spack install gromacs@2020.5 +cuda~mpi+blas %intel ^intel-mkl\n</code></pre> <p>Above command will install gromacs version 2020.5 with blas and cuda support and without MPI support. For blas there are multiple providers like OpenBLAS, Intel MKL, amdblis, and essl, ^intel-mkl will tell spack to use intel-mkl for blas routines.</p> <p>Operators in Spack</p> <p>% to select compiler out of available compilers</p> <p>^   to use variant of package</p> <p>@ to define the version number of packages to be installed.</p> <ul> <li>to enable variant for package</li> </ul> <p>~   to disable variant for package</p>"},{"location":"Page7-LoadingM/#uninstalling-packages","title":"Uninstalling Packages","text":"<p>Earlier we installed many configurations each of zlib. Now we will go through and uninstall some of those packages that we didn\u2019t really need.</p> <pre><code>$ spack uninstall zlib %gcc@6.5.0 (type: y)\n</code></pre>"},{"location":"Page7-LoadingM/#using-environments","title":"Using Environments","text":"<p>Spack has an environment feature in which you can group installed software. You can install software with different versions and dependencies in each environment and can change software to use at once by changing environments. You can create a Spack environment by spack env create command. You can create multiple environments by specifying different environment names here.</p> <pre><code>spack env create myenv\n</code></pre> <p>To activate the created environment, type spack env activate. Adding -p option will display the current activated environment on your console. Then, install software you need to the activated environment.</p> <pre><code>spack env activate -p myenv\n[myenv] [username@es1 ~]$ spack install xxxxx\n</code></pre> <p>You can deactivate the environment by spack env deactivate. To switch to another environment, type spack env activate to activate it.</p> <pre><code>[myenv] [username@es1 ~]$ spack env deactivate [username@es1 ~]$\n</code></pre> <p>Use spack env list to display the list of created Spack environments.</p> <pre><code>[username@es1 ~]$ spack env list\n==&gt; 2 environments myenv another_env\n</code></pre>"},{"location":"Page7-LoadingM/#packaging-for-application-developers","title":"Packaging (For Application developers)","text":"<p>Spack packages are installation scripts, which are essentially recipes for building the software.</p> <p>They define properties and behaviour of the build, such as:</p> <ul> <li>where to find and how to retrieve the software.</li> <li>its dependencies.</li> <li>options for building the software from source; and</li> <li>build commands.</li> </ul> <p>Once we\u2019ve specified a package\u2019s recipe, users of our recipe can ask Spack to build the software with different features on any of the supported systems. Refer Packaging Guide \u2014 Spack 0.22.0 documentation for detailed understanding of the Spack packaging.</p> <p>Example Creating Own Package:</p> <p>In below spec file we have used Linewidth an IISc developed code. See the bold lines for comments related to preceding lines in the spec file of spack package named IiscLinewidth:</p> <pre><code># Copyright 2013-2021 Lawrence Livermore National Security, LLC and other # Spack Project Developers. See the top-level COPYRIGHT file for details. #\n# SPDX-License-Identifier: (Apache-2.0 OR MIT) import os\nimport platform import sys\nimport llnl.util.tty as tty from spack import *\nclass IiscLinewidth(MakefilePackage): \"\"\"\nLinewidth developed by IISC Banglore. \"\"\"\nhomepage = \"\"\n#Url for homepage\nurl = \"file://{0}/linewidth.tar.gz\".format(os.getcwd())\n#Url for source code\nmanual_download = True\n#If source code is not available in public domain\nversion('1', sha256='7215f6765e5f5eddfde5f0c67a5bbdef5960607f3e199a609ef5619278ec8a66',\npreferred=True)\n#You can add different versions for you package.\nvariant('mpi', default=True, description='Install with MPI support') variant('openmp', default=True, description='Install with OpenMP\nsupport')\n#Variant gives flexibility to users for changing parameter before compilation.\ndepends_on('gmake', type='build') depends_on('mpi', when='+mpi') depends_on('hdf5+fortran+hl+mpi') depends_on('intel-mkl') depends_on('py-h5py')\ndepends_on('py-matplotlib', type=('build', 'run'))\n#Depend clause used to specify dependencies for your code.\n@property\ndef build_targets(self): targets = [\n#'--directory=SRC', '--file=Makefile',\n'LIBS={0} {1} '.format(self.spec['intel-mkl'].libs.ld_flags,\nself.spec['hdf5'].libs.ld_flags), 'HDFINCFLAGS={0}'.format(self.spec['hdf5'].prefix.include), 'HDF5_HOME={0}'.format(self.spec['hdf5'].prefix), 'FC={0}'.format(self.spec['mpi'].mpifc)\n]\nreturn targets\ndef install(self, spec, prefix): mkdirp(prefix.bin) install('linewidth', prefix.bin)\n####\n#This code uses Makefile for building application. We can define some properties\n# to make changes in Makefile, changing parameter in Makefile at compile time.\n</code></pre>"},{"location":"Page7-LoadingM/#sample-steps-taken-for-creating-linewidth-application-recipe-for-spack","title":"Sample steps taken for creating linewidth application recipe for Spack","text":"<ul> <li>Source code</li> </ul> <p>Source code of Linewidth was not available through public repo like GitHub, so needed to import OS package.</p> <p>os.getcwd() - expects the source tar present in current working directory. cha256 - to check for sha256 checksum we added same in version clause and for place holder we have given version as 1.</p> <p>manual download = True refers to spack will not try to download source code for the package.</p> <p>name - make sure that name of tar file is same as used inside package recipe</p> <ul> <li>Variant- User can control behavior of application being built through this clause. Ex- To enable MPI support we have defined it to be true by default.</li> <li>depends_on() - This clause defines all dependencies required to build the given application.</li> </ul> <p>Ex- In linewidth example we have used Intel-MKl and HDF5.</p> <ul> <li>@property - With this decorator we can define some properties for build system like edit, build, install.</li> <li>property build_targets - Defines logic of building source for native platform.</li> <li>property install - Defines install procedure to be used after building source code. Ex- In our example we define prefix path</li> </ul>"},{"location":"Page7-LoadingM/#sample-slurm-script-for-openmp-applicationsprograms-to-use-spack","title":"Sample SLURM script for OpenMP applications/programs. to use Spack","text":"<pre><code>#!/bin/bash \n#SBATCH --nodes=1\n#SBATCH -p cpu ## gpu/standard \n#SBATCH --exclusive\n#SBATCH -t 1:00:00\necho \"SLURM_JOBID=\"$SLURM_JOBID\necho \"SLURM_JOB_NODELIST\"=$SLURM_JOB_NODELIST echo \"SLURM_NNODES\"=$SLURM_NNODES\necho \"SLURM_NTASKS\"=$SLURM_NTASKS\nulimit -s unlimited ulimit -c unlimited\nexport OMP_NUM_THREADS=4 ### Maximum number of threads= Number of physical core\n\n#To load necessary application/compiler through spack module load spack\nexport SPACK_ROOT=/home/apps/SPACK/spack\n. $SPACK_ROOT/share/spack/setup-env.sh \nspack load intel-mpi@2019.10.317 /6icwzn3 \nspack load intel-mkl@2020.4.304\nspack load intel-oneapi-compilers@2021.4.0 \nspack load gcc@11.2.0\n(time &lt;executable_path&gt;)\n</code></pre>"},{"location":"Page7-LoadingM/#sample-slurm-script-for-mpi-applicationsprograms-to-use-spack","title":"Sample SLURM script for MPI applications/programs to use Spack","text":"<pre><code>#!/bin/bash \n#SBATCH --nodes=2\n#SBATCH -p cpu ## gpu/standard \n#SBATCH --exclusive\n#SBATCH -t 1:00:00\necho \"SLURM_JOBID=\"$SLURM_JOBID\necho \"SLURM_JOB_NODELIST\"=$SLURM_JOB_NODELIST echo \"SLURM_NNODES\"=$SLURM_NNODES\necho \"SLURM_NTASKS\"=$SLURM_NTASKS\nulimit -s unlimited ulimit -c unlimited\n\n#To load necessary application/compiler through spack module load spack\n\nexport SPACK_ROOT=/home/apps/SPACK/spack\n. $SPACK_ROOT/share/spack/setup-env.sh\nspack load intel-mpi@2019.10.317 /6icwzn3\nspack load intel-mkl@2020.4.304\nspack load intel-oneapi-compilers@2021.4.0 \nspack load gcc@11.2.0\n(time mpirun -np $SLURM_NTASKS &lt;executable_path&gt;)\n</code></pre>"},{"location":"Page8-PreparingE/","title":"Preparing Your Own Executable","text":"<p>The compilations are done on the login node, whereas the execution happens on the compute nodes via the scheduler (SLURM).</p> <p>Note</p> <p> The compilation and execution must be done with the same libraries and matching version to avoid unexpected results. </p> <p>Steps:</p> <ul> <li>Load required modules on the login node.</li> <li>Do the compilation.</li> <li>Open the job submission script and specify the same modules to be loaded as used while compilation.</li> <li>Submit the script.</li> </ul> <p>The directory contains a few sample programs and their sample job submission scripts. The compilation and execution instructions are described in the beginning of the respective files.</p> <p>The user can copy the directory to his/her home directory and further try compiling and executing these sample codes. The command for copying is as follows:</p> <pre><code>cp -r /home/apps/Docs/samples/ ~/.\n</code></pre> <ul> <li>mm.c              - Serial Version of Matrix-Matrix Multiplication of two NxN matrices</li> <li>mm_omp.c      - Basic OpenMP Version of Matrix-Matrix Multiplication of two NxN matrices</li> <li>mm_mpi.c      - Basic MPI Version of Matrix-Matrix Multiplication of two NxN matrices</li> <li>mm_acc.c  - OpenAcc Version of Matrix-Matrix Multiplication of two NxN matrices</li> <li>mm_blas.cu     - CUDA Matrix Multiplication program using the cuBlas library.</li> <li>mm_mkl.c       - MKL Matrix Multiplication program.</li> <li>laplace_acc.c     - OpenACC version of the basic stencil problem.</li> </ul> <p>It is recommended to use the intel compilers since they are better optimized for the hardware.</p> <p>Compilers</p> Compilers Description Versions Available gcc/gfortran GNU Compiler (C/C++/Fortran) 8.5.0, 9.3.0, 12.2.0, 13.2.0 icc/icpc/ifort Intel Compilers (C/C++/Fortran) 2021.5.0, 2021.11.0, 2021.10.0  oneapi@2024.0.0, oneapi@2023.2.0, oneapi@2022.0.0 mpicc/mpicxx/mpif90 Intel-MPIwith GNU compilers (C/C++/Fortran) 2021.11.0 mpiicc/mpiicpc/mpiifort Intel-MPIwithIntel compilers (C/C++/Fortran) 2021.11.0 nvcc CUDA C Compiler 9.1.85, 11.8.0, 12.3.0 <p>Optimization Flags</p> <p>Optimization flags are meant for uniprocessor optimization, wherein, the compiler tries to optimize the program, on the basis of the level of optimization. The optimization flags may also change the precision of output produced from the executable. The optimization flags can be explored more on the respective compiler pages. A few examples are given below.</p> <pre><code>Intel:  -O3 \u2013xHost\nGNU: -O3\nPGI: -fast\n</code></pre> <p>Given next is a brief description of compilation and execution of the various types of programs. However, for certain bigger applications, loading of additional dependency libraries might be required.</p> <p>C Program:</p> <pre><code>Setting up of environment: \nspack load gcc@13.2.0 /3wdooxp\nspack load intel-oneapi-compilers@2024.0.0\ncompilation: icc -O3 -xHost &lt;&lt;prog_name.c&gt;&gt;\nExecution: ./a.out\n</code></pre> <p>C + OpenMP Program:</p> <pre><code>Setting up of environment:  \nspack load gcc@13.2.0 /3wdooxp\nspack load intel-oneapi-compilers@2024.0.0 \nCompilation: icc -O3 -xHost -qopenmp &lt;&lt;prog_name.c&gt;&gt;\nExecution: ./a.out\n</code></pre> <p>C + MPI Program:</p> <pre><code>Setting up of environment:  \nspack load gcc@13.2.0 /3wdooxp\nspack load intel-oneapi-compilers@2024.0.0\nCompilation: mpiicc -O3 -xHost &lt;&lt;prog_name.c&gt;&gt;\nExecution: mpirun -n &lt;&lt;num_procs&gt;&gt; ./a.out\n</code></pre> <p>C + MKL Program:</p> <pre><code>Setting up of environment:\nspack load gcc@13.2.0 /3wdooxp\nspack load intel-oneapi-compilers@2024.0.0\nCompilation: icc -O3 -xHost -mkl &lt;&lt;prog_name.c&gt;&gt;\nExecution: ./a.out\n</code></pre> <p>CUDA Program:</p> <pre><code>Setting up of environment: \nspack load gcc@12.2.0 /h2acmw7\nspack load cuda@12 /qpi4kl6\n\nExample (1)\nCompilation: nvcc -arch=sm_70&lt;&lt;prog_name.cu&gt;&gt;\nExecution: ./a.out \nNote: The optimization switch -arch=sm_70 is intended for Volta V100 GPUs and is valid for CUDA 9 and later. Similarly, older versions of CUDA have compatibility with lower versions of GCC only. Accordingly, appropriate modules of GCC must be loaded. \n\n\nExample (2)\nCompilation: nvcc -arch=sm_70 /home/apps/Docs/samples/mm_blas.cu -lcublas\nExecution: ./a.out\n</code></pre> <p>CUDA OpenMP Program:</p> <pre><code>Setting up of environment: \nspack load gcc@12.2.0 /h2acmw7\nspack load cuda@12 /qpi4kl6\n\nExample (1)\nCompilation: nvcc -arch=sm_70 -Xcompiler=\"-fopenmp\" -lgomp /home/apps/Docs/samples/mm_blas_omp.cu -lcublas\nExecution: ./a.out \n\n\nExample (2)\nCompilation: g++ -fopenmp /home/apps/Docs/samples/mm_blas_omp.c -I//home/apps/SPACK/spack/opt/spack/linux-almalinux8-cascadelake/gcc-12.2.0/cuda-12.3.0-qpi4kl6p2yuvmsvkf4daevk7zcr4tu27/include  -L/home/apps/SPACK/spack/opt/spack/linux-almalinux8-cascadelake/gcc-12.2.0/cuda-12.3.0-qpi4kl6p2yuvmsvkf4daevk7zcr4tu27/lib64 -lcublas\nExecution: ./a.out\n</code></pre> <p>OpenACC Program:</p> <pre><code>Setting up of environment: \nspack load pgi@19.10 cuda@10.1\n\nCompilation for GPU: pgcc -acc -fast -Minfo=all -ta=tesla:cc70,managed/home/apps/Docs/samples/laplace_acc.c\nExecution:./a.out\n\nCompilation for CPU: pgcc -acc -fast -Minfo=all -ta=multicore-tp=skylake /home/apps/Docs/samples/laplace_acc.c\nExecution:./a.out.\n</code></pre>"},{"location":"Page9-Debugging/","title":"Debugging Your Codes","text":""},{"location":"Page9-Debugging/#introduction","title":"Introduction","text":"<p>A debugger or debugging tool is a computer program that is used to test and debug other programs (the \"target\" program).</p> <p>When the program \"traps\" or reaches a preset condition, the debugger typically shows the location in the original code if it is a source-level debugger or symbolic debugger, commonly now seen in integrated development environments.</p> <p>Debuggers also offer more sophisticated functions such as running a program step by step (single-stepping or program animation), stopping (breaking) (pausing the program to examine the current state) at some event or specified instruction by means of a breakpoint, and tracking the values of variables. </p> <p>Some debuggers have the ability to modify program state while it is running. It may also be possible to continue execution at a different location in the program to bypass a crash or logical error.</p>"},{"location":"Page9-Debugging/#basics-how-to","title":"Basics: How To","text":"<p>Compilation</p> <p>Compilation with a separate flag \u2018-g\u2019 is required since the program needs to be linked with debugging symbols.</p> <pre><code>gcc -g &lt;program_name.c&gt;\n\ne.x. gcc -g random_generator.c\n</code></pre> <p>Running the gdb</p> <p>gdb is a command line utility available with almost all Linux systems\u2019 compiler collection packgages.</p> <pre><code>gdb &lt;executable.out&gt;\ne.x. gdb a.out\n</code></pre> <p>Basic gdb commands (to be executed in gdb command line window):</p> <p>Start:</p> <p>Starts the program execution and stops at the first line of the main procedure. Command line arguments may be provided if any. </p> <p>Run: Starts the program execution but does not stop. It stops only when any error or program trap occurs. Command line arguments may be provided if any.</p> <p>Help:  Prints the list of commands available. Specifying \u2018help\u2019 followed by a command (e.x. \u2018help run\u2019) displays more information about that command.</p> <p>File : Loads a binary program that is compiled with \u2018-g\u2019 flag for debugging. <p>List [line_no]</p> <p>Displays the source code (nearby 10 lines) of the program in execution where the execution stopped. If \u2018line_no\u2019 is specified, it displays the source code (10 lines) at the specified line.</p> <p>Info:</p> <p>Displays more information about the set of utilities and saved information by the debugger. For example; \u2018info breakpoints\u2019 will list all the breakpoints, similarly \u2018info watchpoints\u2019 will list all the watchpoints set by the user while debugging their programs.</p> <p>Print &lt; expression &gt;:</p> <p>Prints the values of variables / expression at the current running instance of the program.</p> <p>Step N:</p> <p>Steps the program one (or \u2018N\u2019) instructions ahead or till the program stops for any reason. Steps through each and every instruction even if it is a function call (only function or instruction compiled with debugging flags).</p> <p>next:</p> <p>This command also steps through the instructions of the program. Unlike the \u2018step\u2019 command, if the current source code line calls a subroutine, this command does not enter the subroutine, but instead steps over the call, in effect treating it as a single source line.</p> <p>Continue:</p> <p>This command continues the stopped program till the next breakpoint has occurred or till the end of the program. It is used to continue from a paused/debug point state.</p> <p>Break [sourcefile:]&lt; line_no &gt; [if condition]:</p> <p>Stops the program at the specified line number and provides a breakpoint for the user. Specific source code file and breakpoint based on a condition can also be set for specific cases. You can also view the list of breakpoints set, by using the \u2018info breakpoints\u2019 command.</p> <p>watch &lt; expression &gt;:</p> <p>A watchpoint means break the program or stop the execution of the program when the value of the expression provided is changed. Using watch command specific variables can be watched for value changes. You can also view the list of watchpoints by using the \u2018info watchpoints\u2019 command.</p> <p>Delete &lt; breakpoint number &gt;</p> <p>Delete command deletes a breakpoint or a watchpoint that has been set by a user while debugging the program.</p> <p>Backtrace:</p> <p>Prints the backtrace of all stack frames of the program. Provides the call stack and more other information about the running program.</p> <p>These are some of the most powerful utilities that can be used to debug your programs using gdb. gdb is not limited to these commands and contains a rich set of features that can allow you to debug multi-threaded programs as well. Also, all the commands, along with the ones listed above have \u2018n\u2019 number of different variants for more in-depth control. Same can be utilized using the help page of gdb. </p> <p>Using gdb (example \u2013 inspecting the code)</p> <p>For this case study, we have a small program that generates a long unique random number for each run.</p> <p>Let\u2019s look at the code we have.</p> <p></p> <p>Figure 15 \u2013 Snapshot of debugging process</p> <p>Things to note:</p> <ul> <li>We have a few libraries included for the functions that are used in the program.</li> <li>We have two \u2018#define\u2019 statements:<ul> <li>\u2018N\u2019 for the number of times the \u2018rand_fract\u2019 function will spend in calculating the random number.</li> <li>\u2018N_LEN\u2019 for the length of the final random number string generated. Currently it is set to \u2018100\u2019 which means that the long random number will be of length 100.</li> </ul> </li> <li>Then, we have a function by name \u2018rand_fract\u2019 that iterates over two loops and using the values of iterators (\u2018i\u2019 and \u2018j\u2019), it calculates a small random number. Since, \u2018rand()\u2019 function is used for the outer loop, its number of iterations cannot be clearly defined which gives the function a random nature.</li> <li>The next function is as simple as its name is. It just takes an unsigned integer and returns its factorial.</li> </ul> <p>PART 2:</p> <p></p> <p>Figure 16 \u2013 Snapshot of debugging process</p> <p>Things to note:</p> <ul> <li>This is the main function of the program.</li> <li>The flow of the main function is as follows:<ul> <li>The program first sets a random seed using the process-id of the program.</li> <li>It calls \u2018rand_fract\u2019 function and the resultant random number is operated by a modulo 10 operation. Finally, the result is stored in the variable \u2018f1\u2019.</li> <li>Next the factorial of the obtained \u2018f1\u2019 is calculated and stored in \u2018random_fract\u2019.</li> <li>This result is again passed through a modulo \u2018N_LEN + 1\u2019 and stored in \u2018normalized_fact\u2019.</li> <li>Then a dynamic array is constructed and partially filled with integer values in descending order from the \u2018normalized_fact\u2019 value.</li> <li>Finally, the partial array is printed by mixing the value of the array with rand() function values followed by a modulo 10 operation.</li> <li>The remaining partial part of the final random value is generated using a basic rand() modulo 10 operation.</li> </ul> </li> </ul> <p>Using gdb (example \u2013 using the debugger)</p> <p>The code that we looked upon seems correct, as well as it compiles successfully without any errors. But, when we run this code snippet, this is the result we get.</p> <p></p> <p>Figure 17- Output at a debugging stage</p> <p>The program ended up with a core dump without giving much information but just \u2018Floating point exception\u2019. Now let\u2019s compile the code with debugging information and run the program simply with gdb.</p> <p></p> <p>Figure 18 \u2013 Snapshot of debugging process</p> <p>Here we compiled the code using \u2018-g\u2019 and then used the \u2018run\u2019 command we studied earlier for running the program. You can observe that the debugger stopped at line number 13 where the \u2018Floating point exception (SIGFPE)\u2019 occurred. At this point we can even go and check the code at line number 13. But for now, let\u2019s check what other information we can get from the debugger. Let\u2019s check the values of the variables \u2018i\u2019 and \u2018j\u2019 at this point.</p> <p></p> <p>Figure 19 \u2013 Output depicting \u201cArithmetic Exception\u201d</p> <p>The values of both \u2018i\u2019 and \u2018j\u2019 appear to be \u20180\u2019 and thus a divide by zero exception is what caused our program to terminate. Let\u2019s update the code such that the value of \u2018i\u2019 and \u2018j\u2019 will never become \u20180\u2019. This is the modified code:</p> <p></p> <p>Figure 20 \u2013 Snapshot of debugging process</p> <p>Thus, we just updated the loop index variables to start from \u20181\u2019 instead of \u20180\u2019. Thus, using gdb, it was very simple to identify the point where the error occurred. Let\u2019s re-run our updated code and check what we get.</p> <p></p> <p>Figure 21 \u2013 Well, we dumped core !!</p> <p>What!? This is unexpected. We just cured the error part of our program and still getting an FPE. Let\u2019s go through the debugger and check where the error point is right now.</p> <p></p> <p>Figure 22 - Snapshot of debugging process</p> <p>The debugger output shows that the error occurred on the same line as earlier. But in this case, the value of \u2018i\u2019 and \u2018j\u2019 are not \u20180,0\u2019 but they are \u20181, -1\u2019 which is causing the denominator at line 13 to be \u20180\u2019 and thus, causing an FPE. In addition to print commands, we have also issued the \u2018list\u2019 command which shows the nearby 10 lines of the code where the program stopped.</p> <p>You can observe that some bugs in the programs are easier to debug but some aren\u2019t.</p> <p>We will have to dig in much more to find out what is going on. Also, to be noted, we have our inner loop iterating from 1 to N (which is 100), but still the value of \u2018j\u2019 is printed out to be \u2018-1\u2019. How is this even possible!? Smart programmers would have the problem identified, but let\u2019s stick to the basics on how to gdb. Let us use the \u2018break\u2019 command and set a breakpoint at line number 13 and observe what is going on.</p> <p></p> <p>Figure 23 \u2013 Setting Breakpoint</p> <p>Thus, using the command \u2018break 13\u2019 we have set the breakpoint at line number 13 which was verified using the \u2018info breakpoint\u2019 command. Then, we reran the program with the \u2018run\u2019 command. At line 13 the program stopped and using the \u2018print\u2019 command we checked the values of \u2018i\u2019 and \u2018j\u2019. t this point, all seems to be well. Now, let\u2019s proceed further. For stepping 1 instruction we can use the \u2018step\u2019 command. Let\u2019s do that and observe the value of \u2018j\u2019.</p> <p></p> <p>Figure 24 \u2013 single stepping through to catch error!!</p> <p>You can observe the usage of the \u2018step\u2019 command. We are going through the program line by line and checking the values of the variable \u2018j\u2019.</p> <p>There seems to be a lot of writing/typing of the \u2018step\u2019 command just to proceed with the program. Since we have already set a breakpoint at line 13, we can use another command called \u2018continue\u2019. This command continues the program till the next breakpoint or the end of the program.</p> <p></p> <p>Figure 25 \u2013 Debugging continued</p> <p>You can see that we reduced the typing of the \u2018step\u2019 command by 3 times to a \u2018continue\u2019 command just 1 time. But this is also having us write \u2018continue\u2019 and \u2018print\u2019 multiple times. Let us use some other utility in gdb known as \u2018data breakpoints\u2019 also known as watchpoints. But before that, let us delete the existing breakpoint using the \u2018delete\u2019 command.</p> <p></p> <p>Figure 26 \u2013 Debugging continued</p> <p>Now let us see how to set a watchpoint.</p> <p></p> <p>Figure 27 \u2013 Setting a watchpoint</p> <p>Thus, using the command \u2018watch j\u2019 we have set a watchpoint over \u2018j\u2019. Now every time when the value of \u2018j\u2019 changes, a break will occur. You can also note the old and new values of \u2018j\u2019 printed out at each break. Another point to note is that after having one \u2018continue\u2019 command, the program had a break. Further, by just pressing the \u2018Enter/Return\u2019 button on the keyboard, the continue command was repeated. Thus, by pressing the \u2018Enter/Return\u2019 button, the last command is repeated. At this point, we have learned much about the debugger, but we are still not able to proceed fast with our error. Is there any other way to proceed? Well, yes!!</p> <p>We want to observe at the point where the value of \u2018j\u2019 reaches closer to \u2018N i.e. 100\u2019. Which means that we are only concerned about what happens after \u2018j\u2019 reaches 99. Here, we land up on using what are called conditional breakpoints. First, we will delete our watchpoint and then make use of the conditional breakpoint.</p> <p></p> <p>Figure 28 \u2013 Debugging continued</p> <p>You can observe another variant of the \u2018break\u2019 command. We have explicitly stated the file and the line number along with a condition to stop. This is useful, when the source code is large and has multiple files. After setting a conditional break, we stopped at the point where the value of \u2018j\u2019 becomes \u201899\u2019. Now, let us see what happens next. Since, this is a critical point at which we could observe the program, it is better if we step in the program using the \u2018step\u2019 command instead of relying on any break/watch points.</p> <p></p> <p>Figure 29 \u2013 Well, Back to square one !!</p> <p>This is unexpected!! The value of \u2018j\u2019 should never be 100 or anything above it.</p> <p>Thus, something is wrong with the conditional statement!!</p> <p>By observation, we have figured out that the condition is itself wrong. It should have been \u2018j &lt; N\u2019 instead of \u2018i &lt; N\u2019. This is a silly mistake of the programmer that led us to this much of an effort.</p> <p>Also, the value of \u2018j\u2019 which was observed as \u2018-1\u2019 was an outcome of the \u2018short\u2019 data type overflow i.e. the value of \u2018j\u2019 went from 1 to 32767 (assuming short as 2 bytes) and then from -32768 to -1.</p> <p>Finally, a hard programming bug was discovered. Let us correct this error and rerun the program.</p> <p></p> <p>Figure 30 \u2013 Again, Dumping Core!! Things are getting interesting or frustrating or both!!</p> <p>This is strange!!</p> <p>Sometimes the program is getting the correct output, but sometimes, we are getting a segmentation fault. Debugging such a program may be tricky since the occurrence of the bug is low. We will proceed with our standard debugger steps to identify the error.</p> <p></p> <p>Figure 31 \u2013 Debugging continued</p> <p>We compiled the code and ran it using the debugger. But the program completed successfully. Let us rerun it till a point where the program fails.</p> <p></p> <p>Figure 32 \u2013 Debugging continued</p> <p>Here we observe a point where the program exited at the function \u2018factorial\u2019.</p> <p>This is a point where the debugger didn\u2019t give much information about what the value of the variable \u2018x\u2019 was. It just pointed out that the program failed at the function named \u2018factorial\u2019. That\u2019s it!</p> <p>Another reason for such kind of output would be because of the recursive nature of the function. The stack frame where the function \u2018factorial\u2019 failed could be in a long nest of recursive calls. At such points, it would be better to inspect the program at an earlier point and look for errors. Let us have a breakpoint before the \u2018factorial\u2019 function was called and view the value of the parameters that are passed to the function.</p> <p></p> <p>Figure 33 \u2013 Debugging continued (Will it ever end?)</p> <p>Thus, we have set a breakpoint before the call of the function \u2018factorial\u2019 and run the program. For the value of \u2018f1 = 8\u2019 for the \u2018factorial\u2019 function the process seems to exit normally. Let us rerun.</p> <p></p> <p>Figure 34 \u2013 We are almost there!!</p> <p>Unexpectedly, we have got the value of \u2018f1\u2019 as \u2018-8\u2019 and the program seems to have crashed. Let us observe the \u2018rand_fract\u2019 function and \u2018factorial\u2019 function once again. And study the behavior of the functions where we could get a negative number.</p> <p></p> <p>Figure 35 \u2013 Debugging continued</p> <p>Important points here to observe are:</p> <p>The \u2018rand_fract\u2019 function is returning a datatype of \u2018short\u2019 while the calculation of the return value could be significantly large which may overflow the size of \u2018short\u2019, thus, causing a negative answer.</p> <p>The function \u2018factorial\u2019 is expecting a value of type \u2018unsigned int\u2019. Since the value passed to the function is a negative value, having an implicit conversion from a negative number to an unsigned number means that we are having a very large value passed to the factorial function.</p> <p>Also, since the \u2018factorial\u2019 function is recursive, passing a very large number to it could cause multiple calls to the same function and thus, overflowing the stack provided to the user.</p> <p>Now let us step further into our program and see whether what we are discussing is the same behavior that is being observed.</p> <p></p> <p>Figure 36 \u2013 At last, a clue!!!</p> <p>This is what we had expected.</p> <p>A number \u2018-1\u2019 passed to the \u2018factorial\u2019 function is being implicitly converted to a very large number \u20184294967295\u2019.</p> <p>Stepping in more reveals the recursive behavior of the \u2018factorial\u2019 function i.e. each call is having a sub call to the same function with one value less. Thus, what to do in these types of cases. Assume you have a large code where these functions are called from multiple locations.</p> <p>Modifying the signature of any of the functions means changing the code everywhere where the function is called. This is not affordable. These are some cases, where a choice is to be made where patching the code is necessary for semantics of the program.</p> <p>Let us observe a piece of code where this change can be made and then test our program for the expected results.</p> <p></p> <p>Figure 37 - Correction applied</p> <p>By observing the code, we find out that the expected value of \u2018f1\u2019 is between \u20180 to 9\u2019 (because of the modulo 10 operation).</p> <p>Thus, without changing the signature of any function, we have inserted a patch (the highlighted) portion, that maintains the semantics of the code as well cures the problem that we had. Now let us rerun and check our final program.</p> <p></p> <p>Figure 38 \u2013 Resolved</p> <p>Thus, we are getting the correct results as expected.</p>"},{"location":"Page9-Debugging/#conclusion","title":"Conclusion","text":"<p>We started with a program that we assumed to be functional but then the program ended up with bugs that were not straightforward. We then explored the power of the debugger and the various ways to identify the bugs in our program. We looked upon the easy solutions, and slowly migrated towards the type of bugs that are not easily traceable.</p> <p>Finally, we identified and corrected all the bugs in our program with the help of the debugger and arrived at a bug free code.</p>"},{"location":"Page9-Debugging/#points-to-note","title":"Points to Note","text":"<ul> <li>Bugs in the program cannot be necessarily a compilation error.</li> <li>One type of error can be caused by multiple bugs in the same line of code.</li> <li>Sometimes, it is not possible to change the code even when the problem is identified. The best way to cure this is to study the behavior of the code and apply patches wherever necessary.</li> <li>Using simple utilities from the \u2018GNU Debugger\u2019 can help in getting rid of problems causing bugs in large programs.</li> </ul>"},{"location":"Page9-Debugging/#overall-coding-modifications-done","title":"Overall Coding Modifications Done","text":"<p>Figure 39 \u2013 What all we did to get things right !</p>"},{"location":"Page91-ML-DL/","title":"Machine Learning (ML) / Deep Learning (DL) Application Development","text":"<p>Most of the popular python-based ML/DL libraries are installed on the PARAM Rudra system. Users while developing and testing their applications, can use conda based python installation.</p> <p>For the conda environment different modules are prepared. Users can check the list of the modules by using \u201cmodule avail\u201d command. Shown below is an example of loading conda environments in the current bash shell and continuing with application development. </p> <p>Once logged into PARAM Rudra HPC Cluster, check which all libraries are available, loaded in the current shell. To check list of modules loaded in current shell, use the command given below:</p> <pre><code>$ module list \n</code></pre> <p>To check all modules available on the system, but not loaded currently, use the command given below:</p> <pre><code>$ module avail\n</code></pre> <p>Defaults libraries and framework specific conda environment has been made available for user to start with application development which is installed with most of the popular python packages as shown below</p> <p>Loading the Conda Base Module and Activating the Environments</p> <p>In order to use base conda environment we first, access and load the miniconda module, which provides access to the base environment which is installed with default packages:</p> <pre><code>$ module load miniconda\n</code></pre> <p>To see the list of other packages installed, use the command given below,</p> <pre><code>$ conda list \n</code></pre> <p>We provide multiple conda environments that include basic machine learning packages, as well as common image processing and natural language processing packages, for your machine learning projects.</p> <p>The following table shows currently available conda environments with their version (all include GPU support):</p> Frameworks Environment Version DL Framework Tensorflow Tensorflow 2.15.0 Tensorflow-gpu Tensorflow-gpu 2.15.0 Pytorch Pytorch 2.2.0 Pytorch-gpu Pytorch-gpu 2.2.1 Theano Theano 1.0.5 Theano-gpu Theano-gpu 1.0.5 Caffe Caffe 1.0 Caffe-gpu Caffe-gpu 1.0 Keras Keras 3.0.5 Keras gpu Keras-gpu 3.0.5 Distributed DL Framework Horovod Tensorflow 0.28.1 Pytorch 0.28.1 Data science Framework Rapids Rapids 21.06 <p> To activate any one of the environments we can load it on PARAM Rudra, load module \u201cENV_NAME\u201d as shown below: </p> <pre><code>$ module load &lt;ENV_NAME&gt;\n</code></pre> <p>Once the \u201cENV_NAME\u201d module is loaded, end-users can use all libraries inside their python program.  Users can load those libraries using the \u201cmodule load\u201d command and use them for their applications. </p> <p>Example: To activate Pytorch environment we can load it on PARAM Rudra, using module load Pytorch as shown below: </p> <pre><code>$ module load Pytorch\n</code></pre> <p>This will activate Pytorch environment in which users can use pytorch library and its related functionalities</p> <p>Useful Conda Commands</p> <p>After loading the module, you will have access to conda commands, including:</p> <pre><code>$ conda info --env\n</code></pre> <p>Shows available environments.</p> <pre><code>$ conda list -n env_name\n</code></pre> <p>Shows installed packages within an environment.</p> <pre><code>(env_name)$ conda deactivate\n</code></pre> <p>Deactivates an environment after loading.</p> <p>For more detailed documentation, see the Conda website.</p> <p>Managing and Installing Python Packages in Conda Environments You have two options to install your own Python packages in our machine learning environment:</p> <ul> <li>Use the pip tool to install them directly</li> <li>Build your own conda environment</li> </ul> <p>Consider the benefits and disadvantages of each method, before choosing which works best for you.</p> <p>Note</p> <p> Use Conda primarily for environment management, especially in scientific computing and data science projects where non-Python dependencies are common. </p> <p>Use pip for installing Python packages from PyPI when you don't need the advanced environment management features provided by Conda.</p>"},{"location":"Page91-ML-DL/#building-your-own-conda-environment","title":"Building Your Own Conda Environment","text":"<p>Building your own conda environment gives you the control to manage and install your own packages, and they will be less likely to have version errors than the pip-installed packages. The easiest way to create your own environment is to clone an existing conda environment into your own directory, then modify it.</p> <p>Creating an environment can take up a significant portion of your disk quota, depending on the packages installed. To ensure that you can use your conda environment properly, please familiarize yourself with all the basic conda commands.</p> <p>Conda based installation provides the latest version of DL framework, however users can install their own choice of DL framework or library version locally by following below steps.</p> <pre><code>Step 1. Login to Rudra cluster by using your credential.\n\nStep 2.  Activate conda environment. \n$ module load miniconda\n\nStep 3. Create the local environment myenv  (myenv is the environment name, you can give any name of your choice).\n$ conda create --name myenv\n\nStep 4. Activate a newly created environment. \n$ conda activate myenv\n\nStep 5. Install your own DL framework / python library. &lt;package-name&gt; will get replaced by desired package which user wants to install\n$ conda install &lt;package-name&gt;\nExample: In order to install numpy we can use below command. \n\n$ conda install numpy\nNow you can use the newly installed package in your python program.\n</code></pre>"},{"location":"Page91-ML-DL/#submitting-job-using-sbatch-script-for-dl-application","title":"Submitting job using sbatch script for DL Application","text":"<p>You can activate your machine learning environment, run your program, and deactivate the environment in a SLURM sbatch script. For example:</p> <pre><code>#!/bin/bash -x\n#SBATCH -N 1\n#SBATCH --ntasks-per-node=&lt;np&gt;\n#SBATCH -p cpu\n#SBATCH -J &lt;job_name&gt;\n#SBATCH -t 05:00:00\n#SBATCH -o %j.out             # name of stdout output file(--output)\n#SBATCH -e %j.err             # name of stderr error file(--error)\ncd $SLURM_WORKDIR\nmodule purge\nmodule load miniconda       # load the module and environment\nconda activate &lt;env_name&gt;   # load working environment\npython &lt;script&gt;.py      # run python script\nconda deactivate        # deactivate environment\n# end of script\n</code></pre>"},{"location":"Page91-ML-DL/#how-to-launch-a-jupyter-notebook","title":"How to launch a Jupyter notebook?","text":"<p>You can access the Jupyter notebook from your local system, while it is actually running under the conda virtual environment, setup on a remote server.  It can be accessed through the browser of your local system using ssh tunneling technique. </p> <p>Note</p> <p> To launch the jupyter notebook from gpu, first login to gpu node using the below command in the login node. </p> <pre><code>$ salloc --nodes=1 --time=1:00:00 --gres=gpu:1 --partition=gpu\n</code></pre> <p>To check which gpu node is assigned, use the below command.</p> <pre><code>$ squeue --me\n</code></pre> <p>Now ssh to the node assigned to you. For example, in the screenshot below, you can see that gpu007 was assigned to the user.</p> <pre><code>$ ssh gpu007\n</code></pre> <p>Now to launch the notebook from the gpu node, follow the below steps.</p> <ul> <li>Activate the Conda environment.</li> </ul> <p>To submit the job, use the below command.</p> <pre><code>$ module load miniconda\n</code></pre> <ul> <li>Start the jupyter notebook by below command.</li> </ul> <pre><code>(base)$ jupyter notebook --ip=0.0.0.0 --port=&lt;PORT_NO&gt; --allow-root --no-browser\nFor example,\n(base)$ jupyter notebook --ip=0.0.0.0 --port=8888 --allow-root --no-browser\n</code></pre> <p>Note</p> <p> &gt;Token number displayed on the screen would later be used for login to jupyter notebook through your local web browser. </p> <ul> <li>From another terminal, on your mobaxterm, create ssh tunneling between your local machine and remote system by executing below command</li> </ul> <pre><code>$ ssh -t -t username@&lt;IP_ADDR&gt; -L &lt;PORT_NO&gt;:localhost:&lt;PORT_NO&gt; ssh gpu&lt;NO&gt; -L &lt;PORT_NO&gt;:localhost:&lt;PORT_NO&gt;\n\nFor example,\n$ ssh -p 4422 -t -t appsupport@&lt;IP_ADDR&gt; -L 8888:localhost:8888 ssh gpu007 -L 8888:localhost:8888\n</code></pre> <p>Note</p> <p> Use the port number and gpu node that is assigned by slurm. </p> <ul> <li>Type the below address in your local browser to access Jupyter notebook.</li> </ul> <pre><code>https://localhost:&lt;PORT_NO&gt;\n\nFor example,\nhttps://localhost:8888\nNote: Enter token number for login\n</code></pre> <ul> <li>The Jupyter notebook can now be opened after entering the valid token</li> </ul>"},{"location":"Page911-Enroot/","title":"Enroot for HPC and Deep Learning Applications","text":""},{"location":"Page911-Enroot/#introduction-to-enroot","title":"Introduction to Enroot","text":"<p>What is Enroot ? Enroot is a lightweight containerization technology designed to provide simple, efficient, and secure container execution in High-Performance Computing (HPC) environments. It allows users to run containerized workloads with minimal overhead and maximum portability.</p>"},{"location":"Page911-Enroot/#why-use-enroot-for-deep-learning-in-hpc","title":"Why Use Enroot for Deep Learning in HPC?","text":"<ul> <li> <p> Compatibility with HPC systems:  Enroot integrates seamlessly with HPC schedulers like SLURM, avoiding the need for privileged operations.</p> </li> <li> <p> Lightweight execution:  Enroot has minimal runtime overhead, focusing on simplicity and performance.</p> </li> <li> <p> Security:  Unlike Docker, which requires root privileges, Enroot operates without elevated permissions, making it safer in shared environments.</p> </li> <li> <p> GPU Acceleration:  Enroot supports NVIDIA GPUs, a critical feature for deep learning tasks.</p> </li> <li> <p> Filesystem Isolation:  Enroot uses squashfs images, ensuring efficient storage and access to containerized environments</p> </li> </ul>"},{"location":"Page911-Enroot/#basic-commands-in-enroot","title":"Basic Commands in Enroot","text":"<p>Here are some commonly use Enroot commands:</p> Command Explanation <code>enroot import docker://&lt;image&gt;</code> Downloads a Docker container image and converts it into an Enroot-compatible squashfs image. <code>enroot list</code> Lists all available Enroot container images in the system. <code>enroot create &lt;image&gt;</code> Creates a container from the specified squashfs image. <code>enroot start &lt;container&gt;</code> Starts the specified container and enters its shell. <code>enroot start --mount=&lt;src&gt;:&lt;dst&gt; &lt;container&gt;</code> Starts the container with a host directory mounted inside. <code>enroot remove &lt;container&gt;</code> Deletes a container from the system. <code>enroot exec &lt;container&gt; &lt;command&gt;</code> Executes a single command within the specified container."},{"location":"Page911-Enroot/#sample-slurm-script-with-enroot","title":"Sample SLURM Script with Enroot","text":"<p>Below is an example SLURM script that demonstrates how to download a container image, open it, and run a simple \"Hello, World!\" program.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=enroot_example        # Job name\n#SBATCH --output=hello_world_output.log  # Standard output and error log\n#SBATCH --partition=gpu                  # Partition to use (adjust to your HPC setup)\n#SBATCH \u2013-gres gpu:1                      # Number of GPUs required\n#SBATCH -n 1                       # Number of nodes to be allocated\n#SBATCH --time=00:10:00                  # Maximum run time\n\n# Step 1: Import a container image\necho \"Downloading container image...\"\nenroot import docker://ubuntu:20.04\n\n# Step 2: Create a container\necho \"Creating the container...\"\nenroot create ubuntu+20.04.sqsh\n\n# Step 3: Run a simple program in the container\necho \"Starting the container and running 'Hello, World!'...\"\nenroot exec ubuntu+20.04 /bin/bash -c 'echo \"Hello, World from Enroot!\"'\n</code></pre>"},{"location":"Page911-Enroot/#how-to-run-the-slurm-script","title":"How to Run the SLURM Script","text":"<ul> <li>Save the script as enroot_hello_world.sh.</li> <li>Submit the script using the sbatch command: </li> <li>sbatch enroot_hello_world.sh</li> <li>Check the output in the hello_world_output.log file once the job is complete</li> </ul>"},{"location":"Page911-Enroot/#conclusion","title":"Conclusion","text":"<p>Enroot simplifies running containerized workloads in HPC environments while providing essential features like GPU support and enhanced security. With its minimalistic approach, Enroot is ideal for deep learning applications that require high performance and integration with HPC schedulers like SLURM.</p>"},{"location":"Page911-Enroot/#programs-using-dl-modules","title":"Programs using DL modules","text":"<p>1 . TensorFlow Script for Training a CNN on CIFAR-10</p> <p> Python Script (train_cnn_tf.py) </p> <pre><code>import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\n# Load and preprocess the CIFAR-10 dataset\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\ny_train, y_test = to_categorical(y_train), to_categorical(y_test)\n\n# Build a simple CNN model\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(10, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n\n# Save the model\nmodel.save(\"cnn_cifar10_tf.h5\")\n</code></pre>"},{"location":"Page911-Enroot/#slurm-script-for-tensorflow-run_tf_cnnsh","title":"SLURM Script for TensorFlow (run_tf_cnn.sh)","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=tf_cnn_cifar10         # Job name\n#SBATCH --output=tf_cnn_output.log        # Standard output and error log\n#SBATCH --partition=gpu                   # Partition to use\n#SBATCH -n 1                                # Number of nodes\n#SBATCH \u2013-gres gpu:1                    # Required number of GPUs\n#SBATCH --time=01:00:00                   # Maximum run time\n\n# Load the TensorFlow module or activate your environment\nmodule load mldl_modules/tensorflow_gpu  # Example, adapt to your HPC setup\n\n# Run the training script\npython train_cnn_tf.py\n</code></pre> <p>2 . PyTorch Script for Training a CNN on CIFAR-10</p> <p> Python Script (train_cnn_pytorch.py) </p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\n# Define a simple CNN model\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, activation='relu')\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, activation='relu')\n        self.fc1 = nn.Linear(64 * 6 * 6, 64)\n        self.fc2 = nn.Linear(64, 10)\n\n    def forward(self, x):\n        x = nn.ReLU()(self.conv1(x))\n        x = nn.MaxPool2d(2)(x)\n        x = nn.ReLU()(self.conv2(x))\n        x = nn.MaxPool2d(2)(x)\n        x = torch.flatten(x, 1)\n        x = nn.ReLU()(self.fc1(x))\n        return self.fc2(x)\n\n# Preprocess the CIFAR-10 dataset\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n\n# Initialize the model, loss function, and optimizer\nmodel = CNN().cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\nfor epoch in range(10):\n    model.train()\n    for images, labels in train_loader:\n        images, labels = images.cuda(), labels.cuda()\n\n        optimizer.zero_grad()\n        output = model(images)\n        loss = criterion(output, labels)\n        loss.backward()\n        optimizer.step()\n\n# Save the model\ntorch.save(model.state_dict(), \"cnn_cifar10_pytorch.pth\")\n</code></pre>"},{"location":"Page911-Enroot/#slurm-script-for-pytorch-run_pytorch_cnnsh","title":"SLURM Script for PyTorch (run_pytorch_cnn.sh)","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=pytorch_cnn_cifar10    # Job name\n#SBATCH --output=pytorch_cnn_output.log   # Standard output and error log\n#SBATCH --partition=gpu                   # Partition to use\n#SBATCH \u2013-gres gpu:1                      # Number of GPUs\n#SBATCH --time=01:00:00                   # Maximum run time\n#SBATCH \u2013 n 1                               # Number of nodes to be allocated\n\n# Load the PyTorch module or activate your environment\nmodule load mldl_modules/pytorch_gpu  # Example, adapt to your HPC setup\n\n# Run the training script\npython train_cnn_pytorch.py\n</code></pre>"},{"location":"Page92-ImportantFacts/","title":"Some Important Facts","text":""},{"location":"Page92-ImportantFacts/#about-file-size","title":"About File Size","text":"<p>The global space is served by a number of storage arrays. Each of the storage array contains a portion of the space.  The size of a disk in the storage array is 285TB. Technically, the size of a file can be about 285 TB (which is really big). However, since the disk is shared by a large number of files, effectively the size of a single file will be far smaller. Normally, this file size is kept to be about a few GBs which is sufficient for most of the users.  However, if you wish to have file sizes which are larger than this, you need to create files ACROSS disks and this process is known as \u2018striping\u2019.</p> <pre><code>lfs setstripe -c 4.\n</code></pre> <p>After this has been done all new files created in the current directory will be spread over 4 storage arrays each having 1/4th of the file. The file can be accessed as normal no special action needs to be taken. When the striping is set this way, it will be defined on a per directory basis so different directories can have different stripe setups in the same file system; new subdirectories will inherit the striping from its parent at the time of creation.</p> <p>We recommend users to set the stripe count so that each chunk will be approx. 200-300GB each, for example</p> File Size Stripe count Command 500-1000 GB 4 lfs setstripe -c 4 . 1000 \u2013 2000 GB 8 lfs setstripe -c  8 <p>Once a file is created with a stripe count, it cannot be changed. A user by themselves is also able to set stripe size and stripe count for their directories and A user can check the set stripe size and stripe count with following command:</p> <pre><code>lfs getstripe &lt;path to the direcory&gt;\n</code></pre> <p>To set the stripe count as</p> <pre><code>lfs setstripe -c 4 -s 10m &lt;path to the direcory&gt;\n</code></pre> <p>The options on the above command used have these respective functions.</p> <ul> <li>-c to set the stripe count; 0 means use the system default (usually 1) and -1 means stripe over all available OSTs (lustre Object Storage Targets).</li> <li>-s to set the stripe size; 0 means use the system default (usually 1 MB) otherwise use k, m or g for KB, MB or GB respectively</li> </ul>"},{"location":"Page92-ImportantFacts/#little-endian-and-big-endian-issues","title":"Little-Endian and Big-Endian issues?","text":"<p>By and large, most of the computers follow little-endian format. This essentially means that the last byte of the binary representation of data is stored first. However, there is another way of representing data (used in some machines) where in the first byte of the binary representation of data is stored first. When binary files are to be read across these different kinds of machines, bytes need to be re-ordered. Many compilers do support this feature. Please explore this aspect, if a perfectly working code on a given machine fails to get executed on another machine (with a different processor).</p>"},{"location":"Page93-BestPractices/","title":"Best Practices for HPC","text":"<ul> <li>Do NOT run any job which is longer than a few minutes on the login nodes. Login node is for compilation of jobs. It is best to run the job on compute nodes.</li> <li>It is recommended to go through the beginner\u2019s guide in /home/apps/Docs/samples this should serve as a good starting point for the new users.</li> <li>Use the same compiler to compile different parts/modules/library-dependencies of an application. Using different compilers (e.g. pgcc + icc) to compile different parts of an application may cause linking or execution issues.</li> <li>Choosing appropriate compiler switches/flags/options (e.g. \u2013O3) may increase the performance of the application substantially (accuracy of output must be verified). Please refer to documentation of compilers (online / docs present inside compiler installation path / man pages etc.)</li> <li>Modules/libraries used for execution should be the same as that used for compilations. This can be specified in the Job submission script.</li> <li>Be aware of the amount of disk space utilized by your job(s). Do an estimate before submitting multiple jobs.</li> <li>Please submit jobs preferably in $SCRATCH. You can back up your results/summaries in your $HOME</li> <li>$SCRATCH is NOT backed up! Please download all your data to your Desktop/ Laptop. </li> <li>Before installing any software in your home, ensure that it is from a reliable and safe source. Ransomware is on the rise!</li> <li>Please do not use spaces while creating the directories and files.</li> <li>Please inform PARAM Rudra support when you notice something strange - e.g. unexpected slowdowns, files missing/corrupted etc.</li> </ul>"},{"location":"Page94-InstalledAppl/","title":"Installed Applications","text":"<p>Following is the list of few of the applications from various domains of science and engineering installed in the system.</p> HPC Applications Bio-informatics MUMmer, HMMER, MEME, Schrodinger, PHYLIP, mpiBLAST, ClustalW,  Molecular Dynamics NAMD (for CPU and GPU), LAMMPS, GROMACS  Material Modeling, Quantum Chemistry Quantum-Espresso, Abinit, CP2K, NWChem,  CFD OpenFOAM, SU2  Weather, Ocean, Climate WRF-ARW, WPS (WRF), ARWPost (WRF), RegCM, MOM, ROMS  Deep Learning Libraries cuDNN, TensorFlow,  Tensorflow with Intel Python , Tensorflow with GPU, Theano, Caffe , Keras ,  numpy, Scipy, Scikit-Learn, pytorch.  Visualization Programs GrADS, ParaView, VisIt, VMD  Dependency Libraries NetCDF, PNETCDF, Jasper, HDF5, Tcl, Boost, FFTW"},{"location":"Page94-InstalledAppl/#standard-application-programs-on-param-rudra","title":"Standard Application Programs on PARAM Rudra","text":"<p>The purpose of this section is to expose the users to different application packages which have been installed on PARAM Rudra System. Users interested in exploring these packages may kindly go through the scripts, typical input files and typical output files. It is suggested that at first, the users may submit the scripts provided and get a feel of executing the codes. Later, they may change the parameters and the script to meet their application requirements.</p>"},{"location":"Page94-InstalledAppl/#lammps-applications","title":"LAMMPS Applications","text":"<p>LAMMPS is an acronym for Large-scale Atomic/ Molecular Massively Parallel Simulator. This is extensively used in the fields of Material Science, Physics, Chemistry and many others. More information about LAMMPS may please be found at https://lammps.sandia.gov .</p> <p>\u2981   The LAMMPS input is in.lj  file which contains the below parameters.</p> <pre><code>Input file = in.lj \n\n# 3d Lennard-Jones melt\nvariable        x index 1\nvariable        y index 1\nvariable        z index 1\nvariable        xx equal 64*$x\nvariable        yy equal 64*$y\nvariable        zz equal 64*$z\nunits           lj\natom_style      atomic\nlattice         fcc 0.8442\nregion          box block 0 ${xx} 0 ${yy} 0 ${zz}\ncreate_box      1 box\ncreate_atoms    1 box\nmass            1 1.0\nvelocity        all create 1.44 87287 loop geom\npair_style      lj/cut 2.5\npair_coeff      1 1 1.0 1.0 2.5\nneighbor        0.3 bin\nneigh_modify    delay 0 every 20 check no\n\nfix             1 all nve\nrun             1000000\n</code></pre> <ul> <li>THE LAMMPS RUNNING SCRIPT</li> </ul> <pre><code>#!/bin/sh\n#SBATCH -N 8\n#SBATCH --ntasks-per-node=40\n#SBATCH --time=08:50:20\n#SBATCH --job-name=lammps\n#SBATCH --error=job.%J.err_8_node_40\n#SBATCH --output=job.%J.out_8_node_40\n#SBATCH --partition=standard\nspack load intel-oneapi-compilers /jtvke3n\nspack load intel-oneapi-mpi/2db2e7t\nspack load gcc@13.2.0/3wdooxp\nsource /home/apps/SPACK/spack/opt/spack/linux-almalinux8-cascadelake/gcc-13.2.0/intel-oneapi-mkl-2024.0.0-yq4keqsjr44rf5ffroiiim2iklxg4let/setvars.sh intel64\nexport I_MPI_FALLBACK=disable\nexport I_MPI_FABRICS=shm:ofa\n#export I_MPI_FABRICS=shm:tmi\n#export I_MPI_FABRICS=shm:dapl\nexport I_MPI_DEBUG=5\n#Enter your working directory or use SLURM_SUBMIT_DIR\ncd /home/manjunath/NEW_LAMMPS/lammps-7Aug19/bench\n\nexport OMP_NUM_THREADS=1\ntime mpiexec.hydra -n $SLURM_NTASKS -genv OMP_NUM_THREADS 1 &lt;path of lammps executable&gt; -in in.lj\n</code></pre> <ul> <li>LAMMPS OUTPUT FILE.</li> </ul> <pre><code>LAMMPS (7 Aug 2019)\n  using 1 OpenMP thread(s) per MPI task\nLattice spacing in x,y,z = 1.6796 1.6796 1.6796\nCreated orthogonal box = (0 0 0) to (107.494 107.494 107.494)\n  5 by 8 by 8 MPI processor grid\nCreated 1048576 atoms\n  create_atoms CPU = 0.00387692 secs\nNeighbor list info ...\n  update every 20 steps, delay 0 steps, check no\n  max neighbors/atom: 2000, page size: 100000\n  master list distance cutoff = 2.8\n  ghost atom cutoff = 2.8\n  binsize = 1.4, bins = 77 77 77\n  1 neighbor lists, perpetual/occasional/extra = 1 0 0\n  (1) pair lj/cut, perpetual\n      attributes: half, newton on\n      pair build: half/bin/atomonly/newton\n      stencil: half/bin/3d/newton\n      bin: standard\nSetting up Verlet run ...\n  Unit style    : lj\n  Current step  : 0\n  Time step     : 0.005\nPer MPI rank memory allocation (min/avg/max) = 3.154 | 3.156 | 3.162 Mbytes\nStep Temp E_pair E_mol TotEng Press\n       0         1.44   -6.7733681            0   -4.6133701   -5.0196704\n 1000000   0.65684946   -5.7123998            0   -4.7271266   0.49078272\nLoop time of 2955.97 on 320 procs for 1000000 steps with 1048576 atoms\nPerformance: 146145.063 tau/day, 338.299 timesteps/s\n99.4% CPU use with 320 MPI tasks x 1 OpenMP threads\nMPI task timing breakdown:\nSection |  min time  |  avg time  |  max time  |%varavg| %total\n---------------------------------------------------------------\nPair    | 1284.2     | 1512.3     | 1866.9     | 494.3 | 51.16\nNeigh   | 178.94     | 207.58     | 261.09     | 217.8 |  7.02\nComm    | 793.59     | 1207.7     | 1468.3     | 654.3 | 40.86\nOutput  | 0.00011516 | 0.00084956 | 0.0027411  |   0.0 |  0.00\nModify  | 19.566     | 22.639     | 29.863     |  67.3 |  0.77\nOther   |            | 5.744      |            |       |  0.19\nNlocal:    3276.8 ave 3325 max 3231 min\nHistogram: 4 7 21 63 67 80 50 22 5 1\nNghost:    5011.29 ave 5063 max 4956 min\nHistogram: 5 9 26 45 57 76 51 34 12 5\nNeighs:    122781 ave 127005 max 118605 min\nHistogram: 3 5 36 59 63 52 66 24 11 1\n\nTotal # of neighbors = 39290074\nAve neighs/atom = 37.4699\nNeighbor list builds = 50000\nDangerous builds not checked\nTotal wall time: 0:49:15\n</code></pre>"},{"location":"Page94-InstalledAppl/#gromacs-application","title":"GROMACS APPLICATION","text":""},{"location":"Page94-InstalledAppl/#gromacs","title":"GROMACS","text":"<p>GROningen MAchine for Chemical Simulations\u00a0(GROMACS) is a\u00a0molecular dynamics\u00a0package mainly designed for simulations of\u00a0proteins,\u00a0lipids, and\u00a0nucleic acids. It was originally developed in the Biophysical Chemistry department of\u00a0University of Groningen, and is now maintained by contributors in universities and research centres worldwide.\u00a0GROMACS is one of the fastest and most popular software packages available,\u00a0and can run on\u00a0central processing units\u00a0(CPUs) and\u00a0graphics processing units\u00a0(GPUs).</p> <p>Input description of Gromacs</p> <p>Input file can be download from ftp://ftp.gromacs.org/pub/benchmarks/water_GMX50_bare.tar.gz</p> <p>The mdp option used is pme with 50000 steps</p> <p>Submission Script:</p> <pre><code>#!/bin/sh\n#SBATCH -N 10\n#SBATCH --ntasks-per-node=48\n##SBATCH --time=03:05:30\n#SBATCH --job-name=gromacs\n#SBATCH --error=job.16.%J.err\n#SBATCH --output=job.16.%J.out\n#SBATCH --partition=standard\n\nsource /home/apps/SPACK/spack/share/spack/setup-env.sh\n\nspack load intel-oneapi-compilers /jtvke3n\nspack load gromacs@5.1.4 /73dy73q\n\n#Enter your working directory or use SLURM_SUBMIT_DIR\ncd /home/shweta/water-cut1.0_GMX50_bare/3072\n\nexport I_MPI_DEBUG=5\nexport OMP_NUM_THREADS=1\nmpirun -np 4 gmx_mpi  grompp -f pme.mdp  -c conf.gro -p topol.top\n\ntime mpirun -np $SLURM_NTASKS gmx_mpi mdrun -s topol.tpr) 2&gt;&amp;1 | tee log_gromacs_40_50k_mpirun\n</code></pre> <p>Output Snippet:</p> <pre><code>Number of logical cores detected (48) does not match the number reported by OpenMP (1).\nConsider setting the launch configuration manually!\nRunning on 10 nodes with total 192 cores, 480 logical cores\n  Cores per node:            0 - 48\n  Logical cores per node:   48\nHardware detected on host cn072 (the node of MPI rank 0):\n  CPU info:\n    Vendor: GenuineIntel\n    Brand:  Intel(R) Xeon(R) Platinum 8268 CPU @ 2.90GHz\n    SIMD instructions most likely to fit this hardware: AVX2_256\n    SIMD instructions selected at GROMACS compile time: AVX2_256\nReading file /home/shweta/Gromacs/water-cut1.0_GMX50_bare/3072/topol.tpr, VERSION 5.1.4 (single precision)\nChanging nstlist from 10 to 20, rlist from 1 to 1.032\nThe number of OpenMP threads was set by environment variable OMP_NUM_THREADS to 1 (and the command-line setting agreed with that)\nNOTE: KMP_AFFINITY set, will turn off gmx mdrun internal affinity\n      setting as the two can conflict and cause performance degradation.\n      To keep using the gmx mdrun internal affinity setting, set the\n      KMP_AFFINITY=disabled environment variable.\nOverriding nsteps with value passed on the command line: 50000 steps, 100 ps\nWill use 360 particle-particle and 120 PME only ranks\nThis is a guess, check the performance at the end of the log file\nUsing 480 MPI processes\nUsing 1 OpenMP thread per MPI process\nBack Off! I just backed up ener.edr to ./#ener.edr.2#\nstarting mdrun 'Water'\n50000 steps,    100.0 ps.\n\n Average load imbalance: 5.5 %\n Part of the total run time spent waiting due to load imbalance: 3.0 %\n Average PME mesh/force load: 1.252\n Part of the total run time spent waiting due to PP/PME imbalance: 13.2 %\nNOTE: 13.2 % performance was lost because the PME ranks\n      had more work to do than the PP ranks.\n      You might want to increase the number of PME ranks\n      or increase the cut-off and the grid spacing.\n               Core t (s)   Wall t (s)        (%)\n       Time:   204872.624      427.847    47884.5\n                 (ns/day)    (hour/ns)\nPerformance:       20.195        1.188\n</code></pre>"},{"location":"Page95-Acknowledging/","title":"Acknowledging the National Supercomputing Mission in Publications","text":"<p>If you use supercomputers and services provided under the National Supercomputing Mission, Government of India, please let us know of any published results including Student Thesis, Conference Papers, Journal Papers and patents obtained.</p> <p>Please acknowledge the National Supercomputing Mission as given below:</p> <p>We acknowledge National Supercomputing Mission (NSM) for providing computing resources of \u2018PARAM RUDRA\u2019 at Aruna Asaf Ali Marg, near Vasant Kunj, Vasant Kunj, New Delhi, Delhi 110067, which is implemented by C-DAC and supported by the Ministry of Electronics and Information Technology (MeitY) and Department of Science and Technology (DST), Government of India.</p> <p>Also, please submit the copies of dissertations, reports, reprints and URLs in which \u201cNational Supercomputing Mission, Government of India\u201d is acknowledged to:</p> <p>HPC Technologies, Centre for Development of Advanced Computing, CDAC Innovation Park, S.N. 34/B/1, Panchavati, Pashan, Pune \u2013 411008  Maharashtra </p> <p>Communication of your achievements using resources provided by the National Supercomputing Mission will help the Mission in measuring outcomes and gauging the future requirements. This will also help in further augmentation of resources at a given site of the National Supercomputing Mission.</p>"},{"location":"Page96-Help/","title":"Getting Help \u2013 PARAM Rudra Support","text":"<p>We suggest that you please refer to these four easy steps to generate a Ticket related to the issue you are experiencing.</p> <p>Your Ticket will be assisted by the Rudra Support team. The ticket generated will be closed only when the related issue gets resolved. </p> <p>You can generate a new ticket for any of the new issues that you are experiencing. </p>"},{"location":"Page96-Help/#steps-to-create-a-new-ticket","title":"Steps to Create a New Ticket","text":"<ul> <li>Place the URL https://paramrudra.iitb.ac.in/support in your browser.</li> <li>On the right-top corner of the page click Sign In. Refer to Fig: 36 for the same. </li> </ul> <p>Figure 40 \u2013 Snapshot of Ticketing System</p> <ul> <li>Sign in by using the Username and Password that you use for logging to the Cluster. Refer to Fig37 for the same.</li> </ul> <p></p> <p>Figure 41- Snapshot of Ticketing System</p> <ul> <li>Select a Help Topic from the Dropdown and then Click on Create Ticket. Refer to Fig:38 for the same</li> </ul> <p></p> <p>Figure 42 - Snapshot of Ticketing System</p> <ul> <li>Please fill in the details of your issue in the fields given and then click on Create ticket. </li> </ul> <p></p> <p>Figure 43 - Snapshot of Ticketing System</p> <p>Once the Ticket is generated, an acknowledgement e-mail will be sent to your official e-mail address. The e-mail will also contain the Ticket number along with reference to the ticket that you have generated. </p> <p>In case of any difficulty while accessing Rudra Support you can reach us via e-mail at rudrasupport@iitb.ac.in</p>"},{"location":"Page97-UserCreation/","title":"User Creation Process","text":"<p>To get access to this HPC Facility, proceed with registration on the Portal through the link provided below:</p> <p>Link:  https://services.nsmindia.in/userportal/account </p> <p>Once registered, you will receive an email outlining the next steps to be followed for your User Creation Request.</p> <p>User Creation Portal streamlines the user data collection process, enabling multiple users to submit user creation requests simultaneously. Physical form maintenance is eliminated; users need to provide accurate official details and an email address for procedural notifications. Users can track their account creation status, remaining steps, and identify necessary actions. Administrative or Higher authorities can access all user details through secure login into the portal.</p>"},{"location":"Page97-UserCreation/#processsteps","title":"Process/Steps","text":"<p>Users initiate registration on the portal by entering their email address, city, and institute name. An email will be sent to verify the provided email address, upon verification registration form link is sent for completing the user account request. Users have the option to preview and edit the form before the final submission. Upon submission, a link for Document Upload is provided, where documents like ID proof, User Creation Form and other needed documents are uploaded. Once documents are uploaded, modifications are not possible as the documents will undergo verification processes.</p> <p>User details and documents undergo verification by the user's Institute HOD/PI. Upon approval, a verification email is sent to the coordinator. The coordinator selects the appropriate cluster for the user based on document verification and requirements. Final approval is granted by higher authority, resulting in acceptance of the user request.</p> <p>If you have any queries, refer to the User Creation Manual and Flowcharts accessible in the Help section within the User Creation Portal. Furthermore, common questions are addressed in the FAQ section located beside the Help section. If you have any additional inquiries or require assistance, feel free to reach out to us at nsmsupport@cdac.in.</p> <p>Note</p> <p> Kindly use your official email address for registration to avoid the possibility of your request being declined. </p> <p></p> <p>Figure 43 - Snapshot of Ticketing System</p> <p></p> <p>Figure 44 - User Flow</p> <p></p> <p>Figure 45 - HOD/PI/Co-PI verification Flow</p>"},{"location":"Page98-ClosingAccount/","title":"Closing Your Account on PARAM Rudra","text":"<p>When once you have completed your research work and you no longer need to use PARAM Rudra, you may please close your account on PARAM Rudra. Please raise a ticket by following the URL https://paramrudra.iitb.ac.in/support The system administrator will guide you about the \u201cClosure Procedure\u201d. You will need clearance from your project-coordinator/ Supervisor/ Head of the Department about you having surrendered this resource for getting \u201cno dues\u201d certificate from the institute. </p>"},{"location":"Page99-References/","title":"References","text":"<ul> <li>LAMMPS (Molecular Dynamics Simulations) https://lammps.sandia.gov/</li> <li>https://www.openacc.org/</li> <li>https://www.openmp.org/</li> <li>BLAST (Basic Local Alignment Search Tool) https://blast.ncbi.nlm.nih.gov/Blast.cgi</li> <li>VASP (Vienna Ab initio Simulation Package) https://www.vasp.at/</li> <li>Gaussian (Computational Chemistry Software) https://gaussian.com/</li> <li>https://computing.llnl.gov/tutorials/mpi/</li> <li>CUDA (Parallel Computing Platform and API) https://developer.nvidia.com/cuda-zone</li> <li>https://www.mmm.ucar.edu/weather-research-and-forecasting-model</li> <li>GROMACS (Molecular Dynamics Simulations) http://www.gromacs.org/</li> <li>OpenFOAM (Computational Fluid Dynamics) https://www.openfoam.com/</li> <li>SLURM (Simple Linux Utility for Resource Management) https://slurm.schedmd.com/</li> <li>https://www.tutorialspoint.com/gnu_debugger/what_is_gdb.htm</li> <li>https://nsmindia.in/</li> <li>https://en.wikipedia.org/wiki/Deep_learning</li> <li>https://docs.conda.io/en/latest/miniconda.html</li> <li>https://www.tensorflow.org/</li> <li>https://github.com/PaddlePaddle/Paddle</li> <li>Keras, https://keras.io/</li> <li>Pytorch, https://pytorch.org</li> <li>https://mxnet.apache.org</li> <li>https://software.intel.com/en-us/distribution-for-python</li> <li>https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide</li> <li>NAMD (Molecular Dynamics Simulations) https://www.ks.uiuc.edu/Research/namd/</li> <li>ANSYS (Engineering Simulation Software) https://www.ansys.com/</li> <li>MPI (Message Passing Interface) https://www.mpi-forum.org/</li> <li>AMBER (Assisted Model Building with Energy Refinement) https://ambermd.org/</li> <li>CHARMM (Chemistry at HARvard Macromolecular Mechanics) https://www.charmm.org/</li> </ul>"},{"location":"Installed%20Applications/Domains/CFD/","title":"CFD","text":""},{"location":"Installed%20Applications/Domains/CFD/#computational-fluid-dynamics","title":"Computational Fluid Dynamics","text":""},{"location":"Installed%20Applications/Domains/CFD/#openfoam","title":"OpenFOAM","text":""},{"location":"Installed%20Applications/Domains/CFD/#introduction","title":"Introduction","text":"<p>OpenFOAM is a GPL-opensource C++ CFD-toolbox. This offering is supported</p> <p>by OpenCFD Ltd, producer and distributor of the OpenFOAM software via</p> <p>www.openfoam.com, and owner of the OPENFOAM trademark. OpenCFD Ltd has</p> <p>been developing and releasing OpenFOAM since its debut in 2004.</p> <p>The official website for OpenFOAM:  https://www.openfoam.com/</p>"},{"location":"Installed%20Applications/Domains/CFD/#input","title":"Input","text":"<p>The following example illustrates the running of NWChem with the commonly used data set.</p> <p>Input Data Set link: http://openfoamwiki.net/images/6/62/Motorbike_bench_template.tar.gz</p> <p><code>Wget http://openfoamwiki.net/images/6/62/Motorbike_bench_template.tar.gz</code></p>"},{"location":"Installed%20Applications/Domains/CFD/#slurm-script","title":"Slurm Script","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=\"rfm_job\"\n#SBATCH --ntasks=96\n#SBATCH --ntasks-per-node=48\n#SBATCH --output=rfm_job.out\n#SBATCH --error=rfm_job.err\n#SBATCH --exclusive\n#SBATCH --partition=cpu\nspack load openfoam/ggn7wsm\nspack load intel-oneapi-mpi/3alw73q\nexport OMP_NUM_THREADS=1\ntar --strip-components 2 -xf Motorbike_bench_template.tar.gz bench_template/basecase\n./Allclean\nsed -i -- \"s/method .*/method          scotch;/g\" system/decomposeParDict\nsed -i -- \"s/numberOfSubdomains .*/numberOfSubdomains 96;/g\" system/decomposeParDict\nsed -i -- 's/    #include \"streamLines\"//g' system/controlDict\nsed -i -- 's/    #include \"wallBoundedStreamLines\"//g' system/controlDict\nsed -i -- 's|caseDicts|caseDicts/mesh/generation|' system/meshQualityDict\n./Allmesh\ntime \\\nmpirun -np 96 simpleFoam -parallel\n</code></pre>"},{"location":"Installed%20Applications/Domains/CFD/#anuga","title":"ANUGA","text":""},{"location":"Installed%20Applications/Domains/CFD/#introduction_1","title":"Introduction","text":"<p>The ANUGA Hydrodynamic Model is an open-source software used primarily for simulating the impact of tsunamis, floods, and storm surges in coastal and riverine areas. Developed by the Australian National University (ANU) and Geoscience Australia, ANUGA employs the shallow water wave equations to model the flow of water over complex terrain. The model is widely used for disaster management and planning, allowing detailed simulations of water behavior and predictions in potential flood zones.</p>"},{"location":"Installed%20Applications/Domains/CFD/#input_1","title":"Input","text":"<p>The dataset represents the geographic area of the Mahanadi Delta, India, with actual inputs including tidal data, rainfall data, mesh data, ALOS data, and other necessary inputs. This data uses records from September 12 for simulation purposes. Input files are organized in respective directories in CSV and other compatible formats.</p>"},{"location":"Installed%20Applications/Domains/CFD/#slurm-script_1","title":"Slurm Script","text":"<pre><code>#!/bin/bash                     # Specifies that the script should be executed with the bash shell.\n\n#SBATCH --nodes=4               # Requests 4 compute nodes for the job.\n#SBATCH --ntasks-per-node=46    # Requests 46 tasks per node (assuming a maximum of 48 cores).\n#SBATCH -p standard             # Specifies the partition/queue to be used, such as 'standard' or 'gpu'.\n#SBATCH --time=2-00:00:00       # Sets the maximum job runtime to 2 days.\n##SBATCH --output=mahanadi_delta_.%J.out # Specifies the output file name pattern, using job ID.\n#SBATCH --exclusive             # Requests exclusive access to nodes for optimal resource use.\n\necho \"SLURM_JOBID=\"$SLURM_JOBID          # Prints the SLURM job ID for reference.\necho \"SLURM_JOB_NODELIST\"=$SLURM_JOB_NODELIST # Shows the list of nodes assigned to the job.\necho \"SLURM_NNODES\"=$SLURM_NNODES        # Prints the number of nodes allocated.\necho \"SLURMTMPDIR=\"$SLURMTMPDIR          # Displays the temporary directory path set for this job.\nexport I_MPI_JOB_CONTEXT=$SLURM_JOBID    # Sets MPI job context to the SLURM job ID.\necho SLURM JOB id is $SLURM_JOBID        # Prints the SLURM job ID again for logging.\n\nexport I_MPI_FABRICS=ofi:ofi             # Configures MPI to use the OpenFabrics Interface (OFI).\n\nulimit -s unlimited                      # Removes any limit on stack size.\nulimit -c unlimited                      # Removes any limit on core file size.\nsource /home/apps/SPACK/spack/share/spack/setup-env.sh  # Loads the Spack environment.\nsource ~/miniconda3/bin/activate         # Activates the base Conda environment.\nconda activate anuga-cpu                 # Activates the 'anuga-cpu' Conda environment.\n\nexport I_MPI_DEBUG=9                     # Sets MPI debug level to verbose (9) for debugging.\n\nspack load intel-oneapi-mpi@2021.11.0 /frfogee # Loads the Intel MPI library via Spack, version 2021.11.0.\n\nexport I_MPI_HYDRA_BOOTSTRAP=ssh         # Sets MPI bootstrapping to use SSH.\n\nscontrol show hostname $SLURM_JOB_NODELIST | perl -ne 'chomb; print \"$_\" x4' | uniq -d &gt; h.txt # Creates a list of unique node names.\nsort -ru h.txt &gt; host.txt                # Sorts and removes duplicates from 'h.txt' to create 'host.txt'.\nsed -i 's/$/ slots=46/' host.txt         # Adds 'slots=46' at the end of each line in 'host.txt' for MPI task allocation.\n\ncp host.txt hostfile1                    # Copies 'host.txt' to 'hostfile1'.\ncat hostfile1 | grep hm &gt; hm_hostfile    # Filters hostfile1 for 'hm' nodes and saves them to 'hm_hostfile'.\ncat hostfile1 | grep cn &gt; cn_hostfile    # Filters hostfile1 for 'cn' nodes and saves them to 'cn_hostfile'.\n\nexport I_MPI_HYDRA_BOOTSTRAP=ssh         # Ensures SSH is set as the MPI bootstrap method.\nexport UCX_LOG_LEVEL=info                # Sets UCX (Unified Communication X) logging level to 'info' for detailed logs.\n\n(time mpiexec --hostfile hostfile1 -n $SLURM_NTASKS python run_model_3_samir.py 12-09-2021) 2&gt;&amp;1 | tee demo_12sep\n                                        # Runs the 'run_model_3_samir.py' script on the specified date (12-09-2021) \n                                        # using mpiexec with the hostfile, and redirects output and timing info to 'demo_12sep'.\n\nwhich python                             # Displays the path to the Python interpreter currently in use.\n\n</code></pre>"},{"location":"Installed%20Applications/Domains/CFD/#wrf","title":"WRF","text":""},{"location":"Installed%20Applications/Domains/CFD/#introduction_2","title":"Introduction","text":"<p>WRF is a versatile, high-resolution model widely used for atmospheric research and weather forecasting. It supports both operational forecasts and scientific research applications and has flexible physics options, making it adaptable to various environments and scales.</p>"},{"location":"Installed%20Applications/Domains/CFD/#input_2","title":"Input","text":"<p>Dataset location \u2013 PARAM Rudra IUAC, Delhi /home/apps/hpc_inputs/WRF</p>"},{"location":"Installed%20Applications/Domains/CFD/#slurm-script_2","title":"Slurm Script","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=\"rfm_job\"\n#SBATCH --ntasks=96\n#SBATCH --output=rfm_job.out\n#SBATCH --error=rfm_job.err\n#SBATCH --exclusive\n#SBATCH --partition=hm\n\nspack load intel-oneapi-mpi/bzriwnc\nspack load intel-oneapi-compilers@2023.2.0\nexport OMP_NUM_THREADS=1\n#wget https://www2.mmm.ucar.edu/wrf/users/benchmark/v422/v42_bench_conus2.5km.tar.gz\nulimit -s unlimited\ntar -xvf /home/apps/hpc_inputs/WRF/wrf_run.tar\nml load apps/wrf-4.5.1\ncd run\ntime \\\nmpirun -np 96 wrf.exe\n</code></pre>"},{"location":"Installed%20Applications/Domains/CFD/#amber24","title":"AMBER24","text":""},{"location":"Installed%20Applications/Domains/CFD/#introduction_3","title":"Introduction","text":"<p>Amber (Assisted Model Building with Energy Refinement) is a molecular simulation software suite used for studying the dynamics of biomolecules like proteins, DNA, RNA, and small molecules. It includes tools for system preparation, molecular dynamics simulations, and trajectory analysis, with well-validated force fields and support for both CPU and GPU computations. Amber is widely used for tasks such as energy minimization, molecular dynamics, free energy calculations, and constant pH simulations. It comprises AmberTools (a free suite for setup and analysis) and Amber MD engines (optimized for high-performance simulations on CPUs and GPUs).</p>"},{"location":"Installed%20Applications/Domains/CFD/#slurm-script_3","title":"Slurm Script","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=\"amber\"\n#SBATCH --output=rfm_job.out\n#SBATCH --error=rfm_job.err\n#SBATCH --exclusive\n#SBATCH --partition=cpu\nexport OMP_NUM_THREADS=1\n\n\nmodule load apps/amber24\ncd /home/apps/SourceApps/amber/amber24/AmberTools/examples/PyRESP/test/water/resp\n./py_resp.run\n\n</code></pre>"},{"location":"Installed%20Applications/Domains/MolecularDynamics/","title":"MolecularDynamics","text":""},{"location":"Installed%20Applications/Domains/MolecularDynamics/#molecular-dynamics","title":"Molecular Dynamics","text":""},{"location":"Installed%20Applications/Domains/MolecularDynamics/#gromacs","title":"GROMACS","text":""},{"location":"Installed%20Applications/Domains/MolecularDynamics/#introduction","title":"Introduction","text":"<p>GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles, and is a community-driven project. It is primarily designed for biochemical molecules like proteins, lipids, and nucleic acids that have a lot of complicated bonded interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers and fluid dynamics.</p> <p>The official website for GROMACS: https://www.gromacs.org/</p>"},{"location":"Installed%20Applications/Domains/MolecularDynamics/#input","title":"Input","text":"<p>The following example illustrates the running of GROMACS with the commonly used water_GMX50_bare benchmark data set.</p> <p>Running GROMACS is a two-step process:</p> <ol> <li>Generating the input file (.tpr)</li> <li>Running the generated input files (.tpr)</li> </ol> <p><code>wget http://ftp.gromacs.org/pub/benchmarks/water_GMX50_bare.tar.gz</code></p>"},{"location":"Installed%20Applications/Domains/MolecularDynamics/#slurm-script","title":"Slurm Script","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=\"rfm_job\"\n#SBATCH --ntasks=48\n#SBATCH --ntasks-per-node=48\n#SBATCH --output=rfm_job.out\n#SBATCH --error=rfm_job.err\n#SBATCH --exclusive\n#SBATCH --partition=cpu\nspack load gromacs/m6krxp7\nspack load openmpi/qmzsyj6\ntar -xvf water_GMX50_bare.tar.gz\ncd water-cut1.0_GMX50_bare/3072\ngmx_mpi grompp -f pme.mdp -c conf.gro -p topol.top -o water_pme.tpr\ntime \\\nmpirun -np 48 gmx_mpi  mdrun -nsteps 5000 -s water_pme.tpr\n</code></pre>"},{"location":"Installed%20Applications/Domains/MolecularDynamics/#lammps","title":"LAMMPS","text":""},{"location":"Installed%20Applications/Domains/MolecularDynamics/#introduction_1","title":"Introduction","text":"<p>LAMMPS stands for Large-scale Atomic/Molecular Massively Parallel</p> <p>Simulator.</p> <p>The official website for LAMMPS: https://www.lammps.org/</p>"},{"location":"Installed%20Applications/Domains/MolecularDynamics/#input_1","title":"Input","text":"<p>The following example illustrates the running of LAMMPS with the commonly used data set.</p> <p>Input Data Set link: https://www.lammps.org/bench/inputs/in.lj.txt</p> <pre><code># 3d Lennard-Jones melt\nvariable    x index 1\nvariable    y index 1\nvariable    z index 1\nvariable    xx equal 20*$x\nvariable    yy equal 20*$y\nvariable    zz equal 20*$z\nunits       lj\natom_style  atomic\nlattice     fcc 0.8442\nregion      box block 0 ${xx} 0 ${yy} 0 ${zz}\ncreate_box  1 box\ncreate_atoms    1 box\nmass        1 1.0\nvelocity    all create 1.44 87287 loop geom\npair_style  lj/cut 2.5\npair_coeff  1 1 1.0 1.0 2.5\nneighbor    0.3 bin\nneigh_modify    delay 0 every 20 check no\nfix     1 all nve\nrun     100000\n</code></pre>"},{"location":"Installed%20Applications/Domains/MolecularDynamics/#slurm-script_1","title":"Slurm Script","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=\"rfm_job\"\n#SBATCH --ntasks=192\n#SBATCH --ntasks-per-node=48\n#SBATCH --output=rfm_job.out\n#SBATCH --error=rfm_job.err\n#SBATCH --exclusive\n#SBATCH --partition=hm\nspack load lammps/feqr35c\nspack load intel-oneapi-mpi/3alw73q\nexport OMP_NUM_THREADS=1\ntime \\\nmpirun -np 192 lmp  -in in.lj.txt\n</code></pre>"},{"location":"Installed%20Applications/Domains/MolecularDynamics/#namd","title":"NAMD","text":""},{"location":"Installed%20Applications/Domains/MolecularDynamics/#introduction_2","title":"Introduction","text":"<p>NAMD is a parallel molecular dynamics code designed for high-performance</p> <p>simulation of large biomolecular systems.</p> <p>The official website for NAMD: https://www.ks.uiuc.edu/Research/namd/</p>"},{"location":"Installed%20Applications/Domains/MolecularDynamics/#input_2","title":"Input","text":"<p>The following example illustrates the running of NAMD with the commonly used data set.</p> <p>Input Data Set link: https://www.ks.uiuc.edu/Research/namd/utilities/apoa1.tar.gz</p> <p><code>wget https://www.ks.uiuc.edu/Research/namd/utilities/apoa1.tar.gz</code></p>"},{"location":"Installed%20Applications/Domains/MolecularDynamics/#slurm-script_2","title":"Slurm Script","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=\"rfm_job\"\n#SBATCH --ntasks=48\n#SBATCH --ntasks-per-node=48\n#SBATCH --output=rfm_job.out\n#SBATCH --error=rfm_job.err\n#SBATCH --exclusive\n#SBATCH --partition=cpu\nspack load namd/ynfxnux\nexport OMP_NUM_THREADS=1\ntar -xvf apoa1.tar.gz\ncd apoa1\ntime \\\nmpirun -np 48 namd2 apoa1.namd &amp;&gt; output\n</code></pre>"},{"location":"Installed%20Applications/Domains/Page94-InstalledAppl/","title":"Installed Applications/Libraries","text":"<p>Following is the list of few of the applications from various domains of science and engineering installed in the system.</p> HPC Applications Bio-informatics MUMmer, HMMER, MEME, Schrodinger, PHYLIP, mpiBLAST, ClustalW,  Molecular Dynamics NAMD (for CPU and GPU), LAMMPS, GROMACS  Material Modeling, Quantum Chemistry Quantum-Espresso, Abinit, CP2K, NWChem,  CFD OpenFOAM, SU2  Weather, Ocean, Climate WRF-ARW, WPS (WRF), ARWPost (WRF), RegCM, MOM, ROMS  Deep Learning Libraries cuDNN, TensorFlow,  Tensorflow with Intel Python , Tensorflow with GPU, Theano, Caffe , Keras ,  numpy, Scipy, Scikit-Learn, pytorch.  Visualization Programs GrADS, ParaView, VisIt, VMD  Dependency Libraries NetCDF, PNETCDF, Jasper, HDF5, Tcl, Boost, FFTW"},{"location":"Installed%20Applications/Domains/Page94-InstalledAppl/#standard-application-programs-on-param-rudra","title":"Standard Application Programs on PARAM Rudra","text":"<p>The purpose of this section is to expose the users to different application packages which have been installed on PARAM Rudra System. Users interested in exploring these packages may kindly go through the scripts, typical input files and typical output files. It is suggested that at first, the users may submit the scripts provided and get a feel of executing the codes. Later, they may change the parameters and the script to meet their application requirements.</p>"},{"location":"Installed%20Applications/Domains/Page94-InstalledAppl/#lammps-applications","title":"LAMMPS Applications","text":"<p>LAMMPS is an acronym for Large-scale Atomic/ Molecular Massively Parallel Simulator. This is extensively used in the fields of Material Science, Physics, Chemistry and many others. More information about LAMMPS may please be found at https://lammps.sandia.gov .</p> <p>\u2981   The LAMMPS input is in.lj  file which contains the below parameters.</p> <pre><code>Input file = in.lj \n\n# 3d Lennard-Jones melt\nvariable        x index 1\nvariable        y index 1\nvariable        z index 1\nvariable        xx equal 64*$x\nvariable        yy equal 64*$y\nvariable        zz equal 64*$z\nunits           lj\natom_style      atomic\nlattice         fcc 0.8442\nregion          box block 0 ${xx} 0 ${yy} 0 ${zz}\ncreate_box      1 box\ncreate_atoms    1 box\nmass            1 1.0\nvelocity        all create 1.44 87287 loop geom\npair_style      lj/cut 2.5\npair_coeff      1 1 1.0 1.0 2.5\nneighbor        0.3 bin\nneigh_modify    delay 0 every 20 check no\n\nfix             1 all nve\nrun             1000000\n</code></pre> <ul> <li>THE LAMMPS RUNNING SCRIPT</li> </ul> <pre><code>#!/bin/sh\n#SBATCH -N 8\n#SBATCH --ntasks-per-node=40\n#SBATCH --time=08:50:20\n#SBATCH --job-name=lammps\n#SBATCH --error=job.%J.err_8_node_40\n#SBATCH --output=job.%J.out_8_node_40\n#SBATCH --partition=standard\nspack load intel-oneapi-compilers /jtvke3n\nspack load intel-oneapi-mpi/2db2e7t\nspack load gcc@13.2.0/3wdooxp\nsource /home/apps/SPACK/spack/opt/spack/linux-almalinux8-cascadelake/gcc-13.2.0/intel-oneapi-mkl-2024.0.0-yq4keqsjr44rf5ffroiiim2iklxg4let/setvars.sh intel64\nexport I_MPI_FALLBACK=disable\nexport I_MPI_FABRICS=shm:ofa\n#export I_MPI_FABRICS=shm:tmi\n#export I_MPI_FABRICS=shm:dapl\nexport I_MPI_DEBUG=5\n#Enter your working directory or use SLURM_SUBMIT_DIR\ncd /home/manjunath/NEW_LAMMPS/lammps-7Aug19/bench\n\nexport OMP_NUM_THREADS=1\ntime mpiexec.hydra -n $SLURM_NTASKS -genv OMP_NUM_THREADS 1 &lt;path of lammps executable&gt; -in in.lj\n</code></pre> <ul> <li>LAMMPS OUTPUT FILE.</li> </ul> <pre><code>LAMMPS (7 Aug 2019)\n  using 1 OpenMP thread(s) per MPI task\nLattice spacing in x,y,z = 1.6796 1.6796 1.6796\nCreated orthogonal box = (0 0 0) to (107.494 107.494 107.494)\n  5 by 8 by 8 MPI processor grid\nCreated 1048576 atoms\n  create_atoms CPU = 0.00387692 secs\nNeighbor list info ...\n  update every 20 steps, delay 0 steps, check no\n  max neighbors/atom: 2000, page size: 100000\n  master list distance cutoff = 2.8\n  ghost atom cutoff = 2.8\n  binsize = 1.4, bins = 77 77 77\n  1 neighbor lists, perpetual/occasional/extra = 1 0 0\n  (1) pair lj/cut, perpetual\n      attributes: half, newton on\n      pair build: half/bin/atomonly/newton\n      stencil: half/bin/3d/newton\n      bin: standard\nSetting up Verlet run ...\n  Unit style    : lj\n  Current step  : 0\n  Time step     : 0.005\nPer MPI rank memory allocation (min/avg/max) = 3.154 | 3.156 | 3.162 Mbytes\nStep Temp E_pair E_mol TotEng Press\n       0         1.44   -6.7733681            0   -4.6133701   -5.0196704\n 1000000   0.65684946   -5.7123998            0   -4.7271266   0.49078272\nLoop time of 2955.97 on 320 procs for 1000000 steps with 1048576 atoms\nPerformance: 146145.063 tau/day, 338.299 timesteps/s\n99.4% CPU use with 320 MPI tasks x 1 OpenMP threads\nMPI task timing breakdown:\nSection |  min time  |  avg time  |  max time  |%varavg| %total\n---------------------------------------------------------------\nPair    | 1284.2     | 1512.3     | 1866.9     | 494.3 | 51.16\nNeigh   | 178.94     | 207.58     | 261.09     | 217.8 |  7.02\nComm    | 793.59     | 1207.7     | 1468.3     | 654.3 | 40.86\nOutput  | 0.00011516 | 0.00084956 | 0.0027411  |   0.0 |  0.00\nModify  | 19.566     | 22.639     | 29.863     |  67.3 |  0.77\nOther   |            | 5.744      |            |       |  0.19\nNlocal:    3276.8 ave 3325 max 3231 min\nHistogram: 4 7 21 63 67 80 50 22 5 1\nNghost:    5011.29 ave 5063 max 4956 min\nHistogram: 5 9 26 45 57 76 51 34 12 5\nNeighs:    122781 ave 127005 max 118605 min\nHistogram: 3 5 36 59 63 52 66 24 11 1\n\nTotal # of neighbors = 39290074\nAve neighs/atom = 37.4699\nNeighbor list builds = 50000\nDangerous builds not checked\nTotal wall time: 0:49:15\n</code></pre>"},{"location":"Installed%20Applications/Domains/Page94-InstalledAppl/#gromacs-application","title":"GROMACS APPLICATION","text":""},{"location":"Installed%20Applications/Domains/Page94-InstalledAppl/#gromacs","title":"GROMACS","text":"<p>GROningen MAchine for Chemical Simulations\u00a0(GROMACS) is a\u00a0molecular dynamics\u00a0package mainly designed for simulations of\u00a0proteins,\u00a0lipids, and\u00a0nucleic acids. It was originally developed in the Biophysical Chemistry department of\u00a0University of Groningen, and is now maintained by contributors in universities and research centres worldwide.\u00a0GROMACS is one of the fastest and most popular software packages available,\u00a0and can run on\u00a0central processing units\u00a0(CPUs) and\u00a0graphics processing units\u00a0(GPUs).</p> <p>Input description of Gromacs</p> <p>Input file can be download from ftp://ftp.gromacs.org/pub/benchmarks/water_GMX50_bare.tar.gz</p> <p>The mdp option used is pme with 50000 steps </p> <p>Submission Script:</p> <pre><code>#!/bin/sh\n#SBATCH -N 10\n#SBATCH --ntasks-per-node=48\n##SBATCH --time=03:05:30\n#SBATCH --job-name=gromacs\n#SBATCH --error=job.16.%J.err\n#SBATCH --output=job.16.%J.out\n#SBATCH --partition=standard\n\nsource /home/apps/SPACK/spack/share/spack/setup-env.sh\n\nspack load intel-oneapi-compilers /jtvke3n\nspack load gromacs@5.1.4 /73dy73q\n\n#Enter your working directory or use SLURM_SUBMIT_DIR\ncd /home/shweta/water-cut1.0_GMX50_bare/3072\n\nexport I_MPI_DEBUG=5\nexport OMP_NUM_THREADS=1\nmpirun -np 4 gmx_mpi  grompp -f pme.mdp  -c conf.gro -p topol.top\n\ntime mpirun -np $SLURM_NTASKS gmx_mpi mdrun -s topol.tpr) 2&gt;&amp;1 | tee log_gromacs_40_50k_mpirun\n</code></pre> <p>Output Snippet:</p> <pre><code>Number of logical cores detected (48) does not match the number reported by OpenMP (1).\nConsider setting the launch configuration manually!\nRunning on 10 nodes with total 192 cores, 480 logical cores\n  Cores per node:            0 - 48\n  Logical cores per node:   48\nHardware detected on host cn072 (the node of MPI rank 0):\n  CPU info:\n    Vendor: GenuineIntel\n    Brand:  Intel(R) Xeon(R) Platinum 8268 CPU @ 2.90GHz\n    SIMD instructions most likely to fit this hardware: AVX2_256\n    SIMD instructions selected at GROMACS compile time: AVX2_256\nReading file /home/shweta/Gromacs/water-cut1.0_GMX50_bare/3072/topol.tpr, VERSION 5.1.4 (single precision)\nChanging nstlist from 10 to 20, rlist from 1 to 1.032\nThe number of OpenMP threads was set by environment variable OMP_NUM_THREADS to 1 (and the command-line setting agreed with that)\nNOTE: KMP_AFFINITY set, will turn off gmx mdrun internal affinity\n      setting as the two can conflict and cause performance degradation.\n      To keep using the gmx mdrun internal affinity setting, set the\n      KMP_AFFINITY=disabled environment variable.\nOverriding nsteps with value passed on the command line: 50000 steps, 100 ps\nWill use 360 particle-particle and 120 PME only ranks\nThis is a guess, check the performance at the end of the log file\nUsing 480 MPI processes\nUsing 1 OpenMP thread per MPI process\nBack Off! I just backed up ener.edr to ./#ener.edr.2#\nstarting mdrun 'Water'\n50000 steps,    100.0 ps.\n\n Average load imbalance: 5.5 %\n Part of the total run time spent waiting due to load imbalance: 3.0 %\n Average PME mesh/force load: 1.252\n Part of the total run time spent waiting due to PP/PME imbalance: 13.2 %\nNOTE: 13.2 % performance was lost because the PME ranks\n      had more work to do than the PP ranks.\n      You might want to increase the number of PME ranks\n      or increase the cut-off and the grid spacing.\n               Core t (s)   Wall t (s)        (%)\n       Time:   204872.624      427.847    47884.5\n                 (ns/day)    (hour/ns)\nPerformance:       20.195        1.188\n</code></pre>"},{"location":"Installed%20Applications/Domains/Weather/","title":"Weather","text":""},{"location":"Installed%20Applications/Domains/Weather/#roms","title":"ROMS","text":""},{"location":"Installed%20Applications/Domains/Weather/#introduction","title":"Introduction","text":"<p>ROMS solves the free-surface, hydrostatic, flux form of the primitive equations over variable bathymetry using stretched terrain following in the vertical and orthogonal curvilinear coordinates in the horizontal. The finite volume grid is discretized on a staggered Arakawa C-grid.</p>"},{"location":"Installed%20Applications/Domains/Weather/#input","title":"Input","text":"<p>Dataset location \u2013 PARAM Rudra IUAC, Delhi /home/apps/hpc_inputs/ROMS</p>"},{"location":"Installed%20Applications/Domains/Weather/#slurm-script","title":"Slurm Script","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=\"rfm_job\"\n#SBATCH --ntasks=96\n#SBATCH --output=rfm_job.out\n#SBATCH --error=rfm_job.err\n#SBATCH --exclusive\n#SBATCH --partition=hm\n\nspack load intel-oneapi-mpi/bzriwnc\nspack load intel-oneapi-compilers@2023.2.0\nexport OMP_NUM_THREADS=1\n#wget https://www2.mmm.ucar.edu/wrf/users/benchmark/v422/v42_bench_conus2.5km.tar.gz\nulimit -s unlimited\nml load apps/roms\ncd run\ntime \\\nmpirun -np 96 roms\n</code></pre>"}]}